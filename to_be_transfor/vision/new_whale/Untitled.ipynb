{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipdb\n",
    "from timeit import default_timer as timer\n",
    "from torch.utils.data import DataLoader\n",
    "from data import WhaleData, pic_show\n",
    "from model import Net\n",
    "from loss import FocalLossQb, bce_loss\n",
    "from eval import do_valid, do_valid_arcFace, do_valid_arcFace_preload\n",
    "from lr import CosineAnnealingLR_with_Restart\n",
    "\n",
    "def time_to_str(t, mode='min'):\n",
    "    from timeit import default_timer as timer\n",
    "    if mode=='min':\n",
    "        t  = int(t)/60\n",
    "        hr = t//60\n",
    "        min = t%60\n",
    "        return '%2d hr %02d min'%(hr,min)\n",
    "    elif mode=='sec':\n",
    "        t   = int(t)\n",
    "        min = t//60\n",
    "        sec = t%60\n",
    "        return '%2d min %02d sec'%(min,sec)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join('./models/', 'resnet101')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "if not os.path.exists(os.path.join(out_dir,'checkpoint')):\n",
    "    os.makedirs(os.path.join(out_dir,'checkpoint'))\n",
    "if not os.path.exists(os.path.join(out_dir,'train')):\n",
    "    os.makedirs(os.path.join(out_dir,'train'))\n",
    "        \n",
    "train_dataset = WhaleData(mode='train', augment=True)\n",
    "valid_0 = WhaleData(mode='valid', fold_id=0)\n",
    "valid_1 = WhaleData(mode='valid', fold_id=1)\n",
    "valid_2 = WhaleData(mode='valid', fold_id=2)\n",
    "valid_3 = WhaleData(mode='valid', fold_id=3)\n",
    "valid_4 = WhaleData(mode='valid', fold_id=4)\n",
    "valid_5 = WhaleData(mode='valid', fold_id=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32*12\n",
    "valid_loader0  = DataLoader(valid_0, batch_size=batch_size, drop_last=False, num_workers=6, pin_memory=True)\n",
    "valid_loader1  = DataLoader(valid_1, batch_size=batch_size, drop_last=False, num_workers=6, pin_memory=True)\n",
    "valid_loader2  = DataLoader(valid_2, batch_size=batch_size, drop_last=False, num_workers=6, pin_memory=True)\n",
    "valid_loader3  = DataLoader(valid_3, batch_size=batch_size, drop_last=False, num_workers=6, pin_memory=True)\n",
    "valid_loader4  = DataLoader(valid_4, batch_size=batch_size, drop_last=False, num_workers=6, pin_memory=True)\n",
    "valid_loader5  = DataLoader(valid_4, batch_size=batch_size, drop_last=False, num_workers=6, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "lr = 0.001\n",
    "device = 'cuda'\n",
    "\n",
    "net = Net(model_name='50', num_class=5005, arcFace=True, device=device)\n",
    "for p in net.basemodel.layer0.parameters(): \n",
    "    p.requires_grad = False\n",
    "    \n",
    "for p in net.basemodel.layer1.parameters(): \n",
    "    p.requires_grad = False\n",
    "    \n",
    "for p in net.basemodel.layer2.parameters(): \n",
    "    p.requires_grad = False\n",
    "    \n",
    "net = torch.nn.DataParallel(net)\n",
    "net = net.to(device)\n",
    "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, \n",
    "                            net.parameters()), lr, \n",
    "                            weight_decay=0.0002, momentum=0.9)\n",
    "\n",
    "scheduler = CosineAnnealingLR_with_Restart(optimizer, \n",
    "                                           T_max=4, \n",
    "                                           T_mult=1, \n",
    "                                           model=net, \n",
    "                                           out_dir='./', \n",
    "                                           take_snapshot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = './log_train4.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------EPOCH:0  LR:[0.0008535533905932737]-----------------------------------------\n",
      "train_loss1:0.0000 || train_loss2:0.0000 || train_loss:28.1108 || train_acc:0.0000 ||  use: 0 hr 09 min ||\n",
      "valid_loss1:0.0000 || valid_loss2:0.0000 || valid_loss:28.0395 || valid_acc:0.0000 ||\n",
      "five_sample_label:\n",
      "[3703, 3874, 5004, 3803, 2970]\n",
      "five_sample_predict:\n",
      "[[5004, 1107, 4737, 456, 427], [5004, 4820, 4649, 1338, 2643], [456, 1000, 4195, 3242, 0], [5004, 2797, 2348, 3794, 4358], [5004, 792, 22, 2978, 912]]\n",
      "\n",
      "---------------------------EPOCH:1  LR:[0.0005]-----------------------------------------\n",
      "train_loss1:0.0000 || train_loss2:0.0000 || train_loss:28.0744 || train_acc:0.0026 ||  use: 0 hr 20 min ||\n",
      "valid_loss1:0.0000 || valid_loss2:0.0000 || valid_loss:27.4171 || valid_acc:0.0028 ||\n",
      "five_sample_label:\n",
      "[3762, 1266, 540, 5004, 1747]\n",
      "five_sample_predict:\n",
      "[[5004, 1992, 4405, 824, 2772], [5004, 427, 1780, 62, 2493], [5004, 4019, 824, 4405, 2000], [427, 3604, 2671, 1115, 375], [5004, 2327, 3930, 4405, 4277]]\n",
      "\n",
      "restart at epoch 005\n",
      "---------------------------EPOCH:2  LR:[0.00014644660940672628]-----------------------------------------\n",
      "train_loss1:0.0000 || train_loss2:0.0000 || train_loss:27.5553 || train_acc:0.0458 ||  use: 0 hr 30 min ||\n",
      "valid_loss1:0.0000 || valid_loss2:0.0000 || valid_loss:27.0792 || valid_acc:0.0399 ||\n",
      "five_sample_label:\n",
      "[1214, 5004, 1260, 5004, 1266]\n",
      "five_sample_predict:\n",
      "[[5004, 427, 322, 258, 3589], [82, 97, 4471, 809, 2944], [5004, 2327, 1913, 2134, 1976], [5004, 1554, 4471, 1326, 3604], [5004, 2327, 427, 740, 3057]]\n",
      "\n",
      "---------------------------EPOCH:3  LR:[0.001]-----------------------------------------\n",
      "train_loss1:0.0000 || train_loss2:0.0000 || train_loss:27.7210 || train_acc:0.0408 ||  use: 0 hr 40 min ||\n",
      "valid_loss1:0.0000 || valid_loss2:0.0000 || valid_loss:27.1966 || valid_acc:0.0361 ||\n",
      "five_sample_label:\n",
      "[5004, 748, 4287, 5004, 577]\n",
      "five_sample_predict:\n",
      "[[4471, 1151, 427, 1174, 943], [4413, 62, 5004, 1402, 2944], [5004, 427, 943, 3604, 1108], [943, 1255, 4563, 3393, 3414], [5004, 943, 2425, 4465, 2327]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCH=100\n",
    "i=0\n",
    "        \n",
    "with open(log_file, 'w+') as log:\n",
    "    start = timer()\n",
    "    for epoch in range(EPOCH):\n",
    "        tmp_lr = scheduler.get_lr()\n",
    "        train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, drop_last=False, num_workers=6)\n",
    "        for input, truth_ in train_loader:\n",
    "            logit, loss = net(input.to(device), truth_.to(device))\n",
    "#             batch_loss1 = FocalLossQb(gamma=2)(logit, truth_)\n",
    "#             batch_loss2 = bce_loss(logit, truth_)\n",
    "#             loss = batch_loss1 + batch_loss2\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()                \n",
    "            i+=1\n",
    "            \n",
    "        # epoch eval\n",
    "        scheduler.step()\n",
    "        net.eval()\n",
    "        train_loss1, train_loss2, train_loss, train_acc, label_5, pred_5 = do_valid_arcFace(net, train_loader, device=device) \n",
    "        valid_loss1, valid_loss2, valid_loss, valid_acc, label_5_val, pred_5_val = do_valid_arcFace(net, valid_loader0, device=device)\n",
    "        net.train()\n",
    "        \n",
    "        print('---------------------------EPOCH:{}  LR:{}-----------------------------------------'.format(epoch, tmp_lr))\n",
    "        print('train_loss1:{:.4f} || train_loss2:{:.4f} || train_loss:{:.4f} || train_acc:{:.4f} ||  use:{} ||'.format(train_loss1, train_loss2, train_loss, train_acc, time_to_str((timer() - start), 'min')))\n",
    "        print('valid_loss1:{:.4f} || valid_loss2:{:.4f} || valid_loss:{:.4f} || valid_acc:{:.4f} ||'.format(valid_loss1, valid_loss2, valid_loss, valid_acc))\n",
    "        print('five_sample_label:\\n{}\\nfive_sample_predict:\\n{}\\n'.format(label_5, pred_5))\n",
    "\n",
    "        log.write('---------------------------EPOCH:{}  LR:{}-----------------------------------------'.format(epoch, tmp_lr))\n",
    "        log.write('train_loss1:{:.4f} || train_loss2:{:.4f} || train_loss:{:.4f} || train_acc:{:.4f} ||  use:{} ||'.format(train_loss1, train_loss2, train_loss, train_acc, time_to_str((timer() - start), 'min')))\n",
    "        log.write('valid_loss1:{:.4f} || valid_loss2:{:.4f} || valid_loss:{:.4f} || valid_acc:{:.4f} ||'.format(valid_loss1, valid_loss2, valid_loss, valid_acc))\n",
    "        log.write('five_sample_label:\\n{}\\nfive_sample_predict:\\n{}\\n'.format(label_5, pred_5))\n",
    "        log.write('five_sample_label:\\n{}\\nfive_sample_predict:\\n{}\\n'.format(label_5_val, pred_5_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

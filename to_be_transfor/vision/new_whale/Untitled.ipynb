{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDir = '../data1/'\n",
    "DataListDir = '../new_whale/pic_list/'\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "class WhaleData(Dataset):\n",
    "    def __init__(self, mode='train', fold_id=0, image_size=(128,256)):\n",
    "        super(WhaleData, self).__init__()\n",
    "        assert fold_id in [0,1,2,3,4,5]\n",
    "        assert mode in ['train', 'test', 'valid']\n",
    "        self.pic_dir = '{}/train/'.format(DataDir)\n",
    "        self.mode = mode\n",
    "        self.image_size = image_size\n",
    "        with open(DataListDir+'whale_dict.json', 'r') as f:\n",
    "            self.image_label_dict = json.load(f)\n",
    "        if mode == 'train':\n",
    "            pic_list_path = '{}/train.txt'.format(DataListDir)\n",
    "        elif mode == 'valid':\n",
    "            pic_list_path = '{}/valid_{}.txt'.format(DataListDir, fold_id)\n",
    "        elif mode == 'test':\n",
    "            pic_list_path = '{}/test.txt'.format(DataListDir)\n",
    "        with open(pic_list_path, 'r') as f:\n",
    "#             self.pic_list = f.readlines()[:2**7]\n",
    "            self.pic_list = f.readlines()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode== 'test':\n",
    "            pic_name = self.pic_list[index].split('\\n')[0]\n",
    "            image_path = DataDir+'test/' + pic_name\n",
    "            image = cv2.imread(image_path, 1)\n",
    "            image = cv2.resize(image, (self.image_size[1], self.image_size[0]))\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "            image = image.astype(np.float32)\n",
    "            image = image.reshape([-1, self.image_size[0], self.image_size[1]])\n",
    "            image = image / 255.0\n",
    "            return torch.FloatTensor(image)\n",
    "        else:\n",
    "            pic_name= self.pic_list[index].split(',')[0]\n",
    "            pic_label = self.pic_list[index].split(',')[1].split('\\n')[0]\n",
    "            image_path = DataDir+'train/' + pic_name\n",
    "            image = cv2.imread(image_path, 1)\n",
    "            image = cv2.resize(image, (self.image_size[1], self.image_size[0]))\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "            image = image.astype(np.float32)\n",
    "            image = image.reshape([-1, self.image_size[0], self.image_size[1]])\n",
    "            image = image / 255.0\n",
    "            return torch.FloatTensor(image), self.image_label_dict[pic_label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pic_list)\n",
    "    \n",
    "    \n",
    "# # 1个训练集合, 5个验证集, 1个测试集 先存到本地；\n",
    "# valid 40% new_whale, 60% 随机从 count>=2 里面采样；可以重复；\n",
    "## train 必须拿到所有count==1的，且 其它每个id必须要有至少1个。剩下的是valid池子；\n",
    "\n",
    "# z = pd.read_csv('../data1/train.csv')\n",
    "\n",
    "# 构建 {id:[pics]}\n",
    "# Dic = {}\n",
    "# for i in range(z.shape[0]):\n",
    "#     img, l = z.iloc[i].Image, z.iloc[i].Id\n",
    "#     if l not in Dic:\n",
    "#         Dic[l] = []\n",
    "#         Dic[l].append(img)\n",
    "#     else:\n",
    "#         Dic[l].append(img)\n",
    "        \n",
    "# # 从Dic中采样train\n",
    "# Train_list = []\n",
    "# for i in Dic:\n",
    "#     if i=='new_whale':\n",
    "#         new_whale_train_list = random.sample(Dic[i], 5000)\n",
    "#         Train_list.extend(new_whale_train_list)\n",
    "#     else:\n",
    "#         all_lis = Dic[i]\n",
    "#         leng = len(all_lis)\n",
    "#         if leng==1:\n",
    "#             sample_num=1\n",
    "#         elif leng>1:\n",
    "#             sample_num = leng//2\n",
    "#         else:\n",
    "#             raise Exception('leng==0 not allowed')\n",
    "#         sample_tra_list = random.sample(all_lis, sample_num)\n",
    "#         Train_list.extend(sample_tra_list)\n",
    "\n",
    "# # valid 池子 划分为5个\n",
    "# Valid_list = list(set(z.Image) - set(Train_list)) \n",
    "\n",
    "\n",
    "# import os\n",
    "# dir_path = '/home/qibo/all_project/vision/new_whale/pic_list2'\n",
    "# if not os.path.exists(dir_path):\n",
    "#     os.makedirs(dir_path)\n",
    "\n",
    "# with open('../new_whale/pic_list2/train.txt', 'w+') as f:\n",
    "#     for pic_name in Train_list:\n",
    "#         l = z.set_index('Image').loc[pic_name].Id\n",
    "#         f.write('{},{}\\n'.format(pic_name,l))\n",
    "    \n",
    "\n",
    "# sub_num = len(Valid_list)//5\n",
    "# ZZ = z.set_index('Image')\n",
    "# for fold_id in range(5):\n",
    "#     with open('../new_whale/pic_list2/valid_{}.txt'.format(fold_id), 'w+') as f:\n",
    "#         sub_valid_list = random.sample(Valid_list, sub_num)\n",
    "#         for pic_name in sub_valid_list:\n",
    "#             l = ZZ.loc[pic_name].Id\n",
    "#             f.write('{},{}\\n'.format(pic_name,l))\n",
    "\n",
    "# with open('../new_whale/pic_list2/valid_{}.txt'.format(6), 'w+') as f:\n",
    "#     for pic_name in Valid_list:\n",
    "#         l = ZZ.loc[pic_name].Id\n",
    "#         f.write('{},{}\\n'.format(pic_name,l))\n",
    "\n",
    "# zz = pd.read_csv('../data1/sample_submission.csv')\n",
    "# with open('../new_whale/pic_list2/test.txt', 'w+') as f:\n",
    "#     for line in zz.Image:\n",
    "#         f.write('{}\\n'.format(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model resnet101 \n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as tvm\n",
    "# from data import WhaleData\n",
    "\n",
    "###########################################################################################3\n",
    "class Net(nn.Module):\n",
    "    # 看看to_be_transer_readme, 经典的resnet101一共四层，算上头尾一共6层；\n",
    "\n",
    "    def __init__(self, num_class):\n",
    "        super(Net,self).__init__()      \n",
    "        self.basemodel = tvm.resnet101(pretrained=True)\n",
    "        self.basemodel.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # 这行意思是： 稍后用到 fine_tuning 需要冻结前面两层参数，\n",
    "        # 由于resnet 预训练模型 前四步是 conv+bn+relu+pool, 为了方便，整理到一个layer0中；\n",
    "        self.basemodel.layer0 = nn.Sequential(self.basemodel.conv1,\n",
    "                                              self.basemodel.bn1,             \n",
    "                                              self.basemodel.relu,            \n",
    "                                              self.basemodel.maxpool)         \n",
    "        emb_size = 2048\n",
    "        self.qb_layer = nn.Linear(emb_size, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = [0.485, 0.456, 0.406]  # rgb\n",
    "        std = [0.229, 0.224, 0.225]     \n",
    "\n",
    "        x = torch.cat([\n",
    "            (x[:, [0]] - mean[0]) / std[0], \n",
    "            (x[:, [1]] - mean[1]) / std[1], \n",
    "            (x[:, [2]] - mean[2]) / std[2], \n",
    "        ], 1)\n",
    "\n",
    "        x = self.basemodel.layer0(x)    \n",
    "        x = self.basemodel.layer1(x)    \n",
    "        x = self.basemodel.layer2(x)    \n",
    "        x = self.basemodel.layer3(x)    \n",
    "        x = self.basemodel.layer4(x)    \n",
    "        x = self.basemodel.avgpool(x)\n",
    "        fea = x.view(x.size(0), -1)     \n",
    "        fea = self.qb_layer(fea)\n",
    "        return fea\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    WD = WhaleData(mode='train')\n",
    "    test_sample_2 = torch.cat([WD[0][0].view(1, 3, 128, -1), WD[1][0].view(1, 3, 128, -1)])\n",
    "\n",
    "    resnet = Net(num_class=5005)\n",
    "    logit = resnet(test_sample_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "out_dir = os.path.join('./models/', 'resnet101')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "if not os.path.exists(os.path.join(out_dir,'checkpoint')):\n",
    "    os.makedirs(os.path.join(out_dir,'checkpoint'))\n",
    "if not os.path.exists(os.path.join(out_dir,'train')):\n",
    "    os.makedirs(os.path.join(out_dir,'train'))\n",
    "\n",
    "        \n",
    "train_dataset = WhaleData(mode='train')\n",
    "valid_0 = WhaleData(mode='valid', fold_id=0)\n",
    "valid_1 = WhaleData(mode='valid', fold_id=1)\n",
    "valid_2 = WhaleData(mode='valid', fold_id=2)\n",
    "valid_3 = WhaleData(mode='valid', fold_id=3)\n",
    "valid_4 = WhaleData(mode='valid', fold_id=4)\n",
    "valid_5 = WhaleData(mode='valid', fold_id=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader0  = DataLoader(valid_0, batch_size=batch_size, drop_last=False, num_workers=16)\n",
    "valid_loader1  = DataLoader(valid_1, batch_size=batch_size, drop_last=False, num_workers=16)\n",
    "valid_loader2  = DataLoader(valid_2, batch_size=batch_size, drop_last=False, num_workers=16)\n",
    "valid_loader3  = DataLoader(valid_3, batch_size=batch_size, drop_last=False, num_workers=16)\n",
    "valid_loader4  = DataLoader(valid_4, batch_size=batch_size, drop_last=False, num_workers=16)\n",
    "valid_loader5  = DataLoader(valid_4, batch_size=batch_size, drop_last=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "net = Net(num_class=5005)\n",
    "for p in net.basemodel.layer0.parameters(): \n",
    "    p.requires_grad = False\n",
    "    \n",
    "for p in net.basemodel.layer1.parameters(): \n",
    "    p.requires_grad = False\n",
    "    \n",
    "for p in net.basemodel.layer2.parameters(): \n",
    "    p.requires_grad = False\n",
    "    \n",
    "net = torch.nn.DataParallel(net)\n",
    "net = net.to(device)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "                             lr=0.0001, betas=(0.9, 0.999),\n",
    "                             eps=1e-08, weight_decay=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_per_image(label, predictions):\n",
    "    try:\n",
    "        return 1 / (predictions[:5].index(label) + 1)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "def map_per_set(labels, predictions):\n",
    "    \"\"\"Computes the average over multiple images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : list: ['qb', 'qb', 'zac', 'jam', ... , 'zac']\n",
    "             A list of the true labels. (Only one true label per images allowed!)\n",
    "    predictions : list of list: [['qb', 'zac', 'ben', 'jer', 'gam'], ['qb', 'zac', 'ben', 'jer', 'gam'], ..., ['qb', 'zac', 'ben', 'jer', 'gam']]\n",
    "             A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
    "    \"\"\"\n",
    "    return np.mean([map_per_image(l, list(p)) for l,p in zip(labels, predictions)])\n",
    "\n",
    "\n",
    "def do_valid(net, valid_loader):\n",
    "    loss1_list = []\n",
    "    loss2_list = []\n",
    "    label_list = []\n",
    "    prob_list = []\n",
    "    with torch.no_grad():\n",
    "        for input, truth_, in valid_loader:\n",
    "            input = input.to(device)\n",
    "            truth_ = truth_.to(device)\n",
    "            logit = net(input)\n",
    "            loss1 = FocalLossQb(gamma=2)(logit, truth_)\n",
    "            loss2 = bce_loss(logit, truth_)\n",
    "#             ipdb.set_trace()\n",
    "            _, top5_idx = logit.sigmoid().topk(5)\n",
    "            loss1_list.append(loss1.item())\n",
    "            loss2_list.append(loss2.item())\n",
    "            label_list.extend(truth_.tolist())\n",
    "            prob_list.extend(top5_idx.tolist())\n",
    "    loss1 = np.mean(loss1_list)\n",
    "    loss2 = np.mean(loss2_list)\n",
    "    map_5 = map_per_set(label_list, prob_list)\n",
    "    return loss1, loss2, loss1+loss2, map_5, label_list[:5], prob_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.194912910461426\n",
      "3.9853227138519287\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import ipdb\n",
    "\n",
    "class FocalLossQb(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super(FocalLossQb, self).__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # input: bs, cls;   target: bs, 1\n",
    "\n",
    "        ## 对于其它cls, 其损失，每个样本 num_cls-1 个scalar: loss = - ((pt)**gamma) *(log(1-pt))\n",
    "        ## 目标cls 用了个trick, 计算过程 log(1) = 0, 故不影响；\n",
    "#         ipdb.set_trace()\n",
    "        bs, cls = input.size()\n",
    "        one_hot_target = torch.empty((bs, cls), device=device).zero_()\n",
    "        one_hot_target.scatter_(1, target.view(-1,1), 1) # 把value=1 按照index=target.view(), 根据轴=1，填充到输入里；\n",
    "#         ipdb.set_trace()\n",
    "        pt = 1 - torch.sigmoid(input)*(1-one_hot_target)\n",
    "        loss_other  = -1 * ((1-pt)**self.gamma) * pt.log()\n",
    "\n",
    "        ## 对于目标cls, 其损失，每个样本一个scalar: loss = - ((1-pt)**gamma) *(logpt)\n",
    "        logpt = torch.sigmoid(input).log()\n",
    "        logpt = logpt.gather(1, target.view(-1,1)).view(-1)\n",
    "        loss_target = -1 * ((1-logpt.exp())**self.gamma)*logpt\n",
    "        loss = loss_target.sum() + loss_other.sum()\n",
    "        return loss/bs/cls # 粗略平均，没有考虑目标cls, 此处由于cls=5005, 故不影响\n",
    "\n",
    "def bce_loss(input, target):\n",
    "    bs, cls = input.size()\n",
    "    one_hot_target = torch.empty((bs, cls), device=device).zero_()\n",
    "    one_hot_target.scatter_(1, target.view(-1,1), 1)\n",
    "    loss = F.binary_cross_entropy_with_logits(input, one_hot_target)\n",
    "    return loss\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    batch_size = 4\n",
    "    nb_digits = 10\n",
    "    x = torch.rand(4,10)*random.randint(1,10)\n",
    "    x[0][0]=1\n",
    "    # print(x)\n",
    "\n",
    "    y = torch.LongTensor(batch_size,1).random_() % nb_digits\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    output0 = FocalLossQb(gamma=2)(x,y)\n",
    "    output1 = bce_loss(x,y)\n",
    "\n",
    "    print(output1.item())\n",
    "    print(output0.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "train_loss1:0.0001 || train_loss2:0.0067 || train_loss:0.0067 || train_acc:0.9518 ||\n",
      "valid_loss1:0.0008 || valid_loss2:0.0078 || valid_loss:0.0086 || valid_acc:0.3203 ||\n",
      "five_sample_label:\n",
      "[858, 858, 858, 858, 858]\n",
      "five_sample_predict:\n",
      "[[5004, 858, 4217, 2810, 2170], [5004, 858, 2810, 4217, 2170], [5004, 858, 2810, 4217, 3935], [5004, 858, 4217, 2810, 2170], [5004, 858, 2810, 4217, 3935]]\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "train_loss1:0.0001 || train_loss2:0.0067 || train_loss:0.0068 || train_acc:0.9518 ||\n",
      "valid_loss1:0.0008 || valid_loss2:0.0078 || valid_loss:0.0087 || valid_acc:0.3203 ||\n",
      "five_sample_label:\n",
      "[858, 858, 858, 858, 858]\n",
      "five_sample_predict:\n",
      "[[5004, 858, 4217, 2810, 2170], [5004, 858, 4217, 2810, 2170], [5004, 858, 2810, 4217, 3935], [5004, 858, 4217, 2810, 2170], [5004, 858, 4217, 2810, 3935]]\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "train_loss1:0.0001 || train_loss2:0.0068 || train_loss:0.0068 || train_acc:0.9518 ||\n",
      "valid_loss1:0.0008 || valid_loss2:0.0080 || valid_loss:0.0088 || valid_acc:0.3203 ||\n",
      "five_sample_label:\n",
      "[858, 858, 858, 858, 858]\n",
      "five_sample_predict:\n",
      "[[5004, 858, 4217, 2810, 2170], [5004, 858, 4217, 2810, 2170], [5004, 858, 2810, 4217, 3935], [5004, 858, 4217, 2810, 2170], [5004, 858, 4217, 2810, 3935]]\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "train_loss1:0.0001 || train_loss2:0.0068 || train_loss:0.0069 || train_acc:0.9518 ||\n",
      "valid_loss1:0.0008 || valid_loss2:0.0081 || valid_loss:0.0089 || valid_acc:0.3203 ||\n",
      "five_sample_label:\n",
      "[858, 858, 858, 858, 858]\n",
      "five_sample_predict:\n",
      "[[5004, 858, 4217, 2810, 2170], [5004, 858, 4217, 2810, 2170], [5004, 858, 4217, 2810, 3935], [5004, 858, 4217, 2810, 2170], [5004, 858, 4217, 2810, 3935]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCH=10\n",
    "i=0\n",
    "batch_size=32\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=False, num_workers=16)\n",
    "    for input, truth_ in train_loader:\n",
    "        i+=1\n",
    "        input = input.to(device)\n",
    "        truth_ = truth_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logit = net(input)\n",
    "        batch_loss1 = FocalLossQb(gamma=2)(logit, truth_)\n",
    "        batch_loss2 = bce_loss(logit, truth_)\n",
    "        loss = batch_loss1+batch_loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            net.eval()\n",
    "            train_loss1, train_loss2, train_loss, train_acc, label_5, pred_5 = do_valid(net, train_loader) \n",
    "            valid_loss1, valid_loss2, valid_loss, valid_acc, label_5_val, pred_5_val = do_valid(net, valid_loader0)\n",
    "            net.train()\n",
    "            print('--------------------------------------------------------------------')\n",
    "            print('train_loss1:{:.4f} || train_loss2:{:.4f} || train_loss:{:.4f} || train_acc:{:.4f} ||'.format(train_loss1, train_loss2, train_loss, train_acc))\n",
    "            print('valid_loss1:{:.4f} || valid_loss2:{:.4f} || valid_loss:{:.4f} || valid_acc:{:.4f} ||'.format(valid_loss1, valid_loss2, valid_loss, valid_acc))\n",
    "            print('five_sample_label:\\n{}\\nfive_sample_predict:\\n{}\\n'.format(label_5, pred_5))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

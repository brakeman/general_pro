{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. control sample rate;\n",
    "# 4. mAP\n",
    "\n",
    "# 卡在baseline这里了，因为输出的mask 很奇怪，全0；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # epoch acc\n",
    "\n",
    "# def valid_look(fold_id, pth=None):\n",
    "#     # 由于 img_ori shape 不一致，所以无法放到 loader 里以 batch的形式呈现，因此，bs必须等于1；\n",
    "#     # 之所以要 img_ori, 是因为想要画图展示，想要计算ori_bbox\n",
    "\n",
    "#     if pth is None:\n",
    "#         param = torch.load('./models/unet_49' + '.pth')  # stage3 use model pretrained with pseudo-labels\n",
    "#         model.load_state_dict(param)  # initialize with pretained weight\n",
    "#     model = model.to(device)\n",
    "#     model.eval()\n",
    "#     valid_data_tmp = Jiu_valid(fold_id=fold_id, mode='valid')\n",
    "#     loader = DataLoader(valid_data_tmp,\n",
    "#                             batch_size=1,\n",
    "#                             num_workers=8,\n",
    "#                             pin_memory=True)\n",
    "#     i = 0\n",
    "#     c_pred, c_label_list, bb1_list, bb1_list, img_w, img_h = [],[],[],[],[],[]\n",
    "#     for imgs, mask, C, bbox, H, W, img_ori in progress_bar(loader):   \n",
    "#         i+=1\n",
    "#         if i == 1:\n",
    "#             imgs = imgs.to(device)\n",
    "#             with torch.no_grad():\n",
    "#                 mask_pred = model(imgs).to('cpu').softmax(1).argmax(1)[0] # w, h\n",
    "#                 bbox_pred = mask2bbox_withscale(mask_pred.numpy(), H, W)\n",
    "#                 img = img_ori[0].numpy() # h,w,3\n",
    "#                 x, y, w, h = bbox.numpy()[0]\n",
    "#                 x1, y1, w1, h1 = [i.tolist()[0] for i in bbox_pred]\n",
    "#                 c_label_list.append(C)\n",
    "#                 bb1_list.append([x, y, w, h])\n",
    "#                 bb2_list.append([x1, y1, w1, h1])\n",
    "#                 img_w.append(W)\n",
    "#                 img_h.append(H)\n",
    "#                 if 1:\n",
    "#                     cv2.rectangle(img, (x, y), (x + w, y + h), (1, 0, 0), 2)\n",
    "#                     cv2.rectangle(img, (x1, y1), (x1 + w1, y1 + h1), (0, 0, 1), 2)\n",
    "#                     vis.image(img_gt.transpose((2,0,1)), win='valid1', opts={'title':'valid_gt_{}'.format(C)})\n",
    "#                     vis.image(img_pred.transpose((2,0,1)), win='valid1', opts={'title':'img_pred'})\n",
    "#         else:\n",
    "#             break\n",
    "#         weight_dic = {1:0.15,\n",
    "#                     2:0.09,\n",
    "#                     3:0.09,\n",
    "#                     4:0.05,\n",
    "#                     5:0.13,\n",
    "#                     6:0.05,\n",
    "#                     7:0.12,\n",
    "#                     8:0.13,\n",
    "#                     9:0.07,\n",
    "#                     10:0.12}\n",
    "#     mAp = mAP(weight_dic, c_pred, c_label_list, bb1_list, bb1_list, img_w, img_h)\n",
    "#     return mAp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import ipdb\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from data import JiuData, do_resize, JiuTest\n",
    "from model import *\n",
    "from augment import *\n",
    "from sampler import JiuSampler\n",
    "from loss import multi_class_entropy, lovasz_softmax, FocalLoss2d, DiceLoss2D, FocalLoss2D_2\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from eval import mAP, mask2bbox_withscale, mask2bbox\n",
    "from timeit import default_timer as timer\n",
    "from visdom import Visdom\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def time_to_str(t, mode='min'):\n",
    "    from timeit import default_timer as timer\n",
    "    \n",
    "    if mode=='min':\n",
    "        t  = int(t)/60\n",
    "        hr = t//60\n",
    "        min = t%60\n",
    "        return '%2d hr %02d min'%(hr,min)\n",
    "    elif mode=='sec':\n",
    "        t   = int(t)\n",
    "        min = t//60\n",
    "        sec = t%60\n",
    "        return '%2d min %02d sec'%(min,sec)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def train(loader, model, dataset, device):\n",
    "    model = model.to(device)\n",
    "    running_loss = 0.\n",
    "    model.train()\n",
    "    for imgs, masks, cls, bbox, H, W in progress_bar(loader, parent=mb):\n",
    "        optimizer.zero_grad()\n",
    "#         ipdb.set_trace()\n",
    "        imgs, masks, cls = imgs.to(device), masks.to(device), cls.to(device)\n",
    "        with torch.set_grad_enabled(True):\n",
    "            logits, cls_logits = model(imgs) # [bs, cls, H, W] [bs, cls]\n",
    "#             loss1 = multi_class_entropy(logits, masks.squeeze().int())\n",
    "            loss1 = FocalLoss2D_2(num_class=11, device=device)(logits, masks.squeeze().int())\n",
    "            loss2 = DiceLoss2D(cls_num=11, device=device)(logits, masks.squeeze().int())\n",
    "#             loss2 = lovasz_softmax(logits.squeeze(), masks.squeeze().int(), per_image=False)\n",
    "#             loss3 = torch.nn.CrossEntropyLoss()(cls_logits, cls)\n",
    "            loss = loss1 + loss2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item()*imgs.size(0)\n",
    "    return running_loss/len(dataset)\n",
    "\n",
    "\n",
    "def valid(loader, model, dataset, device):\n",
    "    model = model.to(device)\n",
    "    run_loss, run_loss1, run_loss2, run_loss3 = 0, 0, 0, 0\n",
    "    model.eval()\n",
    "    for imgs, masks, cls, bbox, H, W in progress_bar(loader, parent=mb):    \n",
    "        imgs, masks, cls = imgs.to(device), masks.to(device), cls.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits, cls_logits = model(imgs)\n",
    "#             loss1 = multi_class_entropy(logits, masks.squeeze().int())\n",
    "            loss1 = FocalLoss2D_2(num_class=11, device=device)(logits, masks.squeeze().int())\n",
    "#             loss2 = lovasz_softmax(logits.squeeze(), masks.squeeze().int(), per_image=False)\n",
    "            loss2 = DiceLoss2D(cls_num=11, device=device)(logits, masks.squeeze().int())\n",
    "#             loss3 = torch.nn.CrossEntropyLoss()(cls_logits, cls)\n",
    "            loss = loss1 + loss2\n",
    "        run_loss += loss.item()*imgs.size(0)\n",
    "        run_loss1 += loss1.item()*imgs.size(0)\n",
    "        run_loss2 += loss2.item()*imgs.size(0)\n",
    "        run_loss3 += 0\n",
    "    return run_loss/len(dataset), run_loss1/len(dataset), run_loss2/len(dataset), run_loss3/len(dataset)\n",
    "\n",
    "\n",
    "def valid_look(model, fold_id, epoch, show_num=3, pth=1):\n",
    "    # logit # bs, 11, h, w \n",
    "    # mask_pred\n",
    "    # bbox_pred\n",
    "    # picture\n",
    "    if pth is None:\n",
    "        param = torch.load('./models/unet_49' + '.pth')  # stage3 use model pretrained with pseudo-labels\n",
    "        model.load_state_dict(param)  # initialize with pretained weight\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    valid_data_tmp = JiuData(fold_id=fold_id, mode='valid', return_ori_img=True)\n",
    "    loader = DataLoader(valid_data_tmp,\n",
    "#                         sampler = RandomSampler(valid_data_tmp),\n",
    "                        batch_size=1,\n",
    "                        num_workers=8,\n",
    "                        pin_memory=True)\n",
    "    i = 0\n",
    "    for imgs, mask, C, bbox, H, W, img_ori in loader:   \n",
    "        if i < show_num:\n",
    "            imgs = imgs.to(device)\n",
    "            with torch.no_grad():\n",
    "                mask_pred, cls_logit = model(imgs) # [num_cls, w, h]\n",
    "                mask_pred = mask_pred.to('cpu').softmax(1).argmax(1)[0]\n",
    "                bbox_pred = mask2bbox_withscale(mask_pred.numpy(), H, W)\n",
    "                img  = img_ori[0].numpy() # h,w,3\n",
    "                img_2 = deepcopy(img)\n",
    "                x, y, w, h = bbox.numpy()[0]\n",
    "                x1, y1, w1, h1 = [i.tolist()[0] for i in bbox_pred]\n",
    "                print('mask pred rectangle: {}/{}'.format((x1, y1), (x1 + w1, y1 + h1)))\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (1, 0, 0), 2)\n",
    "                cv2.rectangle(img_2, (x1, y1), (x1 + w1, y1 + h1), (0, 0, 1), 2)\n",
    "#                 ipdb.set_trace()\n",
    "                import matplotlib.pyplot as plt\n",
    "                tmp = np.array([0,1,2])+i*3\n",
    "                plt.subplot(331 + tmp[0])\n",
    "                plt.imshow(mask_pred)\n",
    "                plt.title('mask_epoch:{}'.format(epoch))\n",
    "                \n",
    "                plt.subplot(331 + tmp[1])\n",
    "                plt.imshow(img)\n",
    "                plt.title('val_gt')\n",
    "                \n",
    "                plt.subplot(331 + tmp[2])\n",
    "                plt.imshow(img_2)\n",
    "                plt.title('val_pred_{}'.format(valid_data_tmp.id2cls[C.tolist()[0]]))\n",
    "                \n",
    "                i+=1\n",
    "            vis.matplot(plt) \n",
    "        else:\n",
    "            break\n",
    "    return \n",
    "\n",
    "\n",
    "def infer_upload(pre_train_pth=None):\n",
    "    if pre_train_pth is None:\n",
    "        param = torch.load('./models/unet_49' + '.pth')  # stage3 use model pretrained with pseudo-labels\n",
    "        model.load_state_dict(param)  # initialize with pretained weight\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    dic = {}\n",
    "    dic['images'] = []\n",
    "    dic['annotations']=[]\n",
    "    for index, tup in enumerate(progress_bar(test_loader)):  \n",
    "        name, imgs, ori_h, ori_w = tup\n",
    "        dic['images'].append({'file_name': name,\n",
    "                              'id': index+1})\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        with torch.no_grad():\n",
    "            mask = model(imgs).to('cpu').softmax(1).argmax(1)[0] #w,h\n",
    "            bbox_pred = mask2bbox_withscale(mask.numpy(), ori_h, ori_w)\n",
    "            dic['annotations'].append({'image_id':index+1,\n",
    "                           'bbox':bbox_pred,\n",
    "                           'category_id':mask.max(),\n",
    "                           'score':1})\n",
    "    return dic\n",
    "\n",
    "\n",
    "weight_dic = {1:0.15,\n",
    "2:0.09,\n",
    "3:0.09,\n",
    "4:0.05,\n",
    "5:0.13,\n",
    "6:0.05,\n",
    "7:0.12,\n",
    "8:0.13,\n",
    "9:0.07,\n",
    "10:0.12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "# model = Unet()\n",
    "model = Unet_qb(num_class=11, HyperColumn=True)\n",
    "lr = 0.01\n",
    "min_lr = 0.00015\n",
    "EPOCH=200\n",
    "snapshot = 2\n",
    "scheduler_step = EPOCH//snapshot\n",
    "device = 'cuda'\n",
    "fold_id = 1\n",
    "max_batchs_per_epoch = 300\n",
    "\n",
    "train_data = JiuData(fold_id=fold_id, mode='train', return_ori_img=False)\n",
    "train_loader = DataLoader(\n",
    "                    train_data,\n",
    "#                     sampler=JiuSampler(train_data, bs=batch_size, max_batchs_per_epoch=max_batchs_per_epoch),\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=8,\n",
    "                    pin_memory=True)\n",
    "\n",
    "valid_data = JiuData(fold_id=fold_id, mode='valid', return_ori_img=False)\n",
    "valid_loader = DataLoader(\n",
    "                    valid_data,\n",
    "                    shuffle=RandomSampler(valid_data),\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=8,\n",
    "                    pin_memory=True)\n",
    "\n",
    "testset = JiuTest()\n",
    "test_loader = DataLoader(\n",
    "                    testset,\n",
    "                    batch_size=1,\n",
    "                    num_workers=8,\n",
    "                    pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m visdom.server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "vis = Visdom(env='jiujiu4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='200', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.50% [1/200 02:12<7:20:06]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='177' class='' max='278', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      63.67% [177/278 01:13<00:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask pred rectangle: (0, 0)/(0, 0)\n",
      "mask pred rectangle: (0, 0)/(0, 0)\n",
      "mask pred rectangle: (0, 0)/(0, 0)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(params = model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=scheduler_step, eta_min=min_lr)\n",
    "start = timer()\n",
    "mb = master_bar(range(EPOCH))\n",
    "\n",
    "for epoch in mb:\n",
    "    \n",
    "#     # DEBUG\n",
    "#     if 1:\n",
    "#         PATH='./models/unet_aug01_'+ str(49) + '.pth'\n",
    "#         model.load_state_dict(torch.load(PATH))\n",
    "#         valid_look(model, fold_id)\n",
    "    \n",
    "    # training;\n",
    "    scheduler.step()\n",
    "    epoch_loss = train(train_loader, model, train_data, device)\n",
    "    l_all, l1, l2, l3 = valid(valid_loader, model, valid_data, device)\n",
    "    valid_look(model, fold_id, epoch)\n",
    "    vis.line(X=[epoch], Y=[[scheduler.get_lr()[0], epoch_loss, l_all, l1, l2, l3]], opts=dict(markers=True, showlegend=True), win='loss', update='append' if epoch>0 else None)\n",
    "    \n",
    "\n",
    "    # 重置lr;\n",
    "    if (epoch + 1) % scheduler_step == 0:\n",
    "        torch.save(model.state_dict(),  './models/unet_qb_aug_focal'+ str(epoch) + '.pth')\n",
    "        optimizer = torch.optim.SGD(params = model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=scheduler_step, eta_min=min_lr)\n",
    "        scheduler.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

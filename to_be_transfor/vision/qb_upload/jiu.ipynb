{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. control sample rate;\n",
    "# 4. mAP \n",
    "\n",
    "\n",
    "# 1. valid set 做infer upload\n",
    "# 2. json 文件评估准确度；\n",
    "# 3. 跟线上 map 比较；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import ipdb\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from data2 import Jiu2Data\n",
    "from data import JiuData, do_resize, JiuTest, JiuValid\n",
    "from model import *\n",
    "from augment import *\n",
    "from sampler import JiuSampler\n",
    "from loss import multi_class_entropy, lovasz_softmax, FocalLoss2d, DiceLoss2D, FocalLoss2D_2\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from eval import *\n",
    "from timeit import default_timer as timer\n",
    "from visdom import Visdom\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def time_to_str(t, mode='min'):\n",
    "    from timeit import default_timer as timer\n",
    "    \n",
    "    if mode=='min':\n",
    "        t  = int(t)/60\n",
    "        hr = t//60\n",
    "        min = t%60\n",
    "        return '%2d hr %02d min'%(hr,min)\n",
    "    elif mode=='sec':\n",
    "        t   = int(t)\n",
    "        min = t//60\n",
    "        sec = t%60\n",
    "        return '%2d min %02d sec'%(min,sec)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def train(loader, model, dataset, device):\n",
    "    model = model.to(device)\n",
    "    running_loss = 0.\n",
    "    model.train()\n",
    "    for imgs, masks, H, W in progress_bar(loader, parent=mb):\n",
    "        optimizer.zero_grad()\n",
    "#         ipdb.set_trace()\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        with torch.set_grad_enabled(True):\n",
    "            logits, cls_logits = model(imgs) # [bs, cls, H, W] [bs, cls]\n",
    "#             loss1 = multi_class_entropy(logits, masks.squeeze().int())\n",
    "            loss1 = FocalLoss2D_2(num_class=num_class, device=device)(logits, masks.squeeze().int())\n",
    "#             loss2 = DiceLoss2D(cls_num=11, device=device)(logits, masks.squeeze().int())\n",
    "#             loss2 = lovasz_softmax(logits.squeeze(), masks.squeeze().int(), per_image=False)\n",
    "#             loss3 = torch.nn.CrossEntropyLoss()(cls_logits, cls)\n",
    "            loss = loss1 \n",
    "            print(loss1, logits.sum())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item()*imgs.size(0)\n",
    "    return running_loss/len(dataset)\n",
    "\n",
    "\n",
    "def valid(loader, model, dataset, device):\n",
    "    model = model.to(device)\n",
    "    run_loss, run_loss1, run_loss2, run_loss3 = 0, 0, 0, 0\n",
    "    model.eval()\n",
    "    for imgs, masks, H, W in progress_bar(loader, parent=mb):    \n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits, cls_logits = model(imgs)\n",
    "#             loss1 = multi_class_entropy(logits, masks.squeeze().int())\n",
    "            loss1 = FocalLoss2D_2(num_class=num_class, device=device)(logits, masks.squeeze().int())\n",
    "            \n",
    "#             loss2 = lovasz_softmax(logits.squeeze(), masks.squeeze().int(), per_image=False)\n",
    "#             loss2 = DiceLoss2D(cls_num=11, device=device)(logits, masks.squeeze().int())\n",
    "#             loss3 = torch.nn.CrossEntropyLoss()(cls_logits, cls)\n",
    "            \n",
    "            loss = loss1\n",
    "        run_loss += loss.item()*imgs.size(0)\n",
    "#         run_loss1 += loss1.item()*imgs.size(0)\n",
    "#         run_loss2 += loss2.item()*imgs.size(0)\n",
    "#         run_loss3 += 0\n",
    "    return run_loss/len(dataset), run_loss1/len(dataset), run_loss2/len(dataset), run_loss3/len(dataset)\n",
    "\n",
    "\n",
    "def valid_look(model, fold_id, epoch, show_num=3, pth=1):\n",
    "    # logit # bs, 11, h, w \n",
    "    # mask_pred\n",
    "    # bbox_pred\n",
    "    # picture\n",
    "    if pth is None:\n",
    "        param = torch.load('./models/unet_49' + '.pth')  # stage3 use model pretrained with pseudo-labels\n",
    "        model.load_state_dict(param)  # initialize with pretained weight\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    valid_data_tmp = Jiu2Data(fold_id=fold_id, mode='valid', return_ori_img=True)\n",
    "    loader = DataLoader(valid_data_tmp,\n",
    "#                         sampler = RandomSampler(valid_data_tmp),\n",
    "                        batch_size=1,\n",
    "                        num_workers=8,\n",
    "                        pin_memory=True)\n",
    "    i = 0\n",
    "    for imgs, mask, H, W, img_ori in loader:   \n",
    "        if i < show_num:\n",
    "            imgs = imgs.to(device)\n",
    "            with torch.no_grad():\n",
    "                mask_pred, cls_logit = model(imgs) # [num_cls, w, h]\n",
    "                mask_pred = mask_pred.to('cpu').softmax(1).argmax(1)[0]\n",
    "                bbox_pred = mask2bbox_withscale(mask_pred.numpy(), H, W)\n",
    "                img  = img_ori[0].numpy() # h,w,3\n",
    "                \n",
    "                img_2 = deepcopy(img)\n",
    "                x, y, w, h = [int(i) for i in bbox.numpy()[0]]\n",
    "                x1, y1, w1, h1 = [int(i) for i in bbox_pred]\n",
    "                print('mask pred rectangle: {}/{}'.format((x1, y1), (x1 + w1, y1 + h1)))\n",
    "                print('mask real rectangle: {}/{}'.format((x, y), (x + w, y + h)))\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (1, 0, 0), 2)\n",
    "                cv2.rectangle(img_2, (x1, y1), (x1 + w1, y1 + h1), (0, 0, 1), 2)\n",
    "#                 ipdb.set_trace()\n",
    "                import matplotlib.pyplot as plt\n",
    "                tmp = np.array([0,1,2])+i*3\n",
    "                plt.subplot(331 + tmp[0])\n",
    "                plt.imshow(mask_pred)\n",
    "                plt.title('mask_epoch:{}'.format(epoch))\n",
    "                \n",
    "                plt.subplot(331 + tmp[1])\n",
    "                plt.imshow(img)\n",
    "                plt.title('val_gt')\n",
    "                \n",
    "                plt.subplot(331 + tmp[2])\n",
    "                plt.imshow(img_2)\n",
    "                plt.title('val_pred_{}'.format(valid_data_tmp.id2cls[C.tolist()[0]]))\n",
    "                \n",
    "                i+=1\n",
    "            vis.matplot(plt) \n",
    "        else:\n",
    "            break\n",
    "    return \n",
    "\n",
    "\n",
    "weight_dic = {1:0.15,\n",
    "2:0.09,\n",
    "3:0.09,\n",
    "4:0.05,\n",
    "5:0.13,\n",
    "6:0.05,\n",
    "7:0.12,\n",
    "8:0.13,\n",
    "9:0.07,\n",
    "10:0.12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "num_class = 24\n",
    "model = Unet_qb(num_class=num_class, HyperColumn=True)\n",
    "lr = 0.01\n",
    "min_lr = 0.005\n",
    "EPOCH=200\n",
    "snapshot = 3\n",
    "scheduler_step = EPOCH//snapshot\n",
    "device = 'cuda'\n",
    "fold_id = 1\n",
    "max_batchs_per_epoch = 300\n",
    "\n",
    "train_data = Jiu2Data(fold_id=fold_id, mode='train')\n",
    "train_loader = DataLoader(\n",
    "                    train_data,\n",
    "                    shuffle=RandomSampler(train_data),\n",
    "#                     sampler=JiuSampler(train_data, bs=batch_size, max_batchs_per_epoch=max_batchs_per_epoch),\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=8,\n",
    "                    pin_memory=True)\n",
    "\n",
    "valid_data = Jiu2Data(fold_id=fold_id, mode='valid')\n",
    "valid_loader = DataLoader(\n",
    "                    valid_data,\n",
    "                    shuffle=RandomSampler(valid_data),\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=8,\n",
    "                    pin_memory=True)\n",
    "\n",
    "img_path = './chongqing1_round1_train1_20191223/images/'\n",
    "test_img_path = './chongqing1_round1_testA_20191223/images/'\n",
    "\n",
    "testset = JiuTest(test_img_path=test_img_path)\n",
    "test_loader = DataLoader(\n",
    "                    testset,\n",
    "                    batch_size=1,\n",
    "                    num_workers=8,\n",
    "                    pin_memory=True)\n",
    "\n",
    "# validset = JiuValid(fold_id=fold_id)\n",
    "# valid_infer_loader = DataLoader(\n",
    "#                     validset,\n",
    "#                     batch_size=1,\n",
    "#                     num_workers=8,\n",
    "#                     pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m visdom.server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "vis = Visdom(env='Friday1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='200', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/200 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='46' class='' max='46', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [46/46 00:14<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.8439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(300820.4062, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5.2347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(173793.7812, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4.4053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(36317.3555, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3.7915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-166669.1719, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3.4061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-517090.4688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3.1423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-1103831.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.8275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-1810875., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2.1819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2685516., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.8732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2765015.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.6514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2878430., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2794463., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.2160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-3004017.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.4248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2826002.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.0299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2590909.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.2955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2629429., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2581155.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2727866.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2640810., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2356414., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.0344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2365862.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.9266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2241365.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.0597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-1995987., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.5212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2006768.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-1951014.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-2061340.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-1695703.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-1751566.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-1787116.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-1551861.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-1248939.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-1085709.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.3243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-785791., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.5259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(257201.7812, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.1714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-641024.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.4208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-479730.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-229650.9219, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-333823.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-424803.4062, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.5206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-492571.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-40612.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.3733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-790717.3125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-411128.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-430149.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(146285.7656, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.9034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(18983.3184, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(295204.4688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-193910.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-145573.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.3685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(209516.2656, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.4530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-442699.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-123846.9531, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-364559.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.6845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(593388.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-940856.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-810654.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.2039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-723914.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-568497.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-84921.9531, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-686425.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-7011.8613, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.1853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-258933.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(311692.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.2651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-291969.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.2048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-481485., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.2198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-346513.4062, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.9612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-190250.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-342467.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.3415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-96990.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(124856.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-747738.1250, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-94274.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(736916.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.9539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-497114.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(509993.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-399946.3438, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(716395.5625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.0405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-848045.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(127462.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-260398.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-369573.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-81556.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(79249.5938, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.9878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(600341.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(205855.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(83589.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(455141.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-479471.2188, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-432588.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1265052.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.2968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-1076345.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-14933.3984, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.4761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-20007.0547, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(692853.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-358.2227, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(546094.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.3377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(366489.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(835084.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14864.4805, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.2478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(235448.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(271203.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(450860.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-273354.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1331105., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-392476.5625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(230638.7188, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(778223.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.2654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(899532.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-99625.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-11987., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.9430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(187241.8594, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(827796.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-167439.5625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-184089.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(422167.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-476564.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-427020.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-231217.7656, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-163075.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(357625.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(614144.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(508014.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(586995.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(320081.5938, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(825411.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(441455.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13610.2109, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(417033.5625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(417852.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-609755., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(777635.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(189080.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-316864., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-248944.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(493398.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13994.3945, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(982123.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-18634.9609, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-291995.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(453667.5312, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.2132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(195790.2812, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-411399.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-74997.5234, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-410285.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-296551.3438, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(384215.3125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-290120.3438, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-219330.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(642346.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1.0858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-920988.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(957982.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-274336.3125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15504.4414, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.8283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-66340.2266, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(126063.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-187232.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-251465.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-337331.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-687435.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-525477.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-187335.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-132401., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-595105.3125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(88793.7734, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(225126.3594, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-220983.0156, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11037.3047, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-108378.0781, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(37591.8359, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(240499.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-589130.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-198177.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.5127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(131455.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-623765., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-17328.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(565937.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-469755.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.2652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-496184.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-902984.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.4412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-494622.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-383044.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0.3042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(-69572.5625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "0.8473019451935734\n",
      "-------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'valid_infer_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6da9c6346145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0ml_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_mAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_infer_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#     valid_look(model, fold_id, epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshowlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'append'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_infer_loader' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(params = model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=scheduler_step, eta_min=min_lr)\n",
    "start = timer()\n",
    "mb = master_bar(range(EPOCH))\n",
    "for epoch in mb:\n",
    "    \n",
    "# DEBUG\n",
    "# if 1:\n",
    "#     PATH='./models/unet_qb_aug_focal'+ str(99) + '.pth'\n",
    "#     model.load_state_dict(torch.load(PATH))\n",
    "#     valid_look(model, fold_id, epoch=111)\n",
    "\n",
    "\n",
    "#     training;\n",
    "    scheduler.step()\n",
    "    epoch_loss = train(train_loader, model, train_data, device)\n",
    "    print(epoch_loss)\n",
    "    print('-------')\n",
    "    l_all, l1, l2, l3 = valid(valid_loader, model, valid_data, device)\n",
    "    mAP = eval_mAP(loader=valid_infer_loader, model=model)\n",
    "#     valid_look(model, fold_id, epoch)\n",
    "    vis.line(X=[epoch], Y=[[scheduler.get_lr()[0], mAP, epoch_loss, l_all, l1, l2, l3]], opts=dict(markers=True, showlegend=True), win='loss', update='append' if epoch>0 else None)\n",
    "    \n",
    "#     重置lr;\n",
    "    if (epoch + 1) % scheduler_step == 0:\n",
    "        torch.save(model.state_dict(),  './models/unet_qb_aug_focal'+ str(epoch) + '.pth')\n",
    "        optimizer = torch.optim.SGD(params = model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=scheduler_step, eta_min=min_lr)\n",
    "        scheduler.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='170' class='' max='181', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      93.92% [170/181 01:31<00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qibo/qb_vir_env/lib/python3.6/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.063295749871587e-07 4.650514602661133\n",
      "9.905241256690258e-07 4.835926055908203\n",
      "1.08254002805358e-06 5.6113972663879395\n",
      "1.1831038557962623e-06 4.589935302734375\n",
      "1.2930096784658604e-06 4.1842780113220215\n",
      "1.413125331656678e-06 4.372176647186279\n",
      "1.5443992695701398e-06 5.557719707489014\n",
      "1.6878680541750162e-06 4.795699596405029\n",
      "1.8446645400819847e-06 4.770511150360107\n",
      "2.016026819761732e-06 4.739486217498779\n",
      "2.2033079997395975e-06 5.322046756744385\n",
      "2.4079868849613086e-06 4.957401275634766\n",
      "2.6316796556954193e-06 5.6952805519104\n",
      "2.876152629175321e-06 4.8528666496276855\n",
      "3.143336206748985e-06 4.703388214111328\n",
      "3.435340116665557e-06 5.017614841461182\n",
      "3.7544700728585323e-06 4.6367082595825195\n",
      "4.103245981266156e-06 4.908940315246582\n",
      "4.48442183744935e-06 4.403446197509766\n",
      "4.901007472622241e-06 4.683043003082275\n",
      "5.356292319805727e-06 4.361291885375977\n",
      "5.853871387765822e-06 5.71571159362793\n",
      "6.397673647831499e-06 4.436385631561279\n",
      "6.991993057739342e-06 4.415324687957764\n",
      "7.64152246747469e-06 4.861566543579102\n",
      "8.351390674835727e-06 5.102718353271484\n",
      "9.127202923317734e-06 5.100692272186279\n",
      "9.975085162095885e-06 4.749173641204834\n",
      "1.0901732417591131e-05 4.716984748840332\n",
      "1.1914461658569542e-05 5.041261196136475\n",
      "1.302126957220715e-05 4.296144008636475\n",
      "1.4230895707330217e-05 4.774556636810303\n",
      "1.5552891483421002e-05 5.557662487030029\n",
      "1.6997695610296174e-05 5.096892833709717\n",
      "1.857671651398489e-05 4.637149810791016\n",
      "2.0302422419655617e-05 4.353522300720215\n",
      "2.2188439802902313e-05 4.686776161193848\n",
      "2.424966098677848e-05 4.284486293792725\n",
      "2.6502361734184132e-05 4.925408840179443\n",
      "2.8964329764135665e-05 4.714420318603516\n",
      "3.165500520670564e-05 4.549962520599365\n",
      "3.4595634105689225e-05 4.5557475090026855\n",
      "3.780943618108112e-05 5.188697338104248\n",
      "4.132178817604494e-05 5.0606513023376465\n",
      "4.5160424236114684e-05 4.822612285614014\n",
      "4.9355654902857575e-05 5.42029333114624\n",
      "5.394060645121046e-05 4.951694488525391\n",
      "5.89514824603393e-05 4.687561511993408\n",
      "6.442784968343093e-05 4.732048988342285\n",
      "7.041295047369499e-05 4.381581783294678\n",
      "7.695404423354644e-05 4.529661655426025\n",
      "8.410278058311086e-05 4.411843776702881\n",
      "9.191560719465667e-05 4.325109004974365\n",
      "0.000100454215513286 4.3165178298950195\n",
      "0.00010978602788337265 4.2683024406433105\n",
      "0.00011998472992718323 5.289771556854248\n",
      "0.00013113085237943524 4.763632297515869\n",
      "0.00014331240697206034 5.1164679527282715\n",
      "0.00015662558139022988 5.069890975952148\n",
      "0.00017117549878713646 4.979686260223389\n",
      "0.00018707704785479395 4.95412015914917\n",
      "0.00020445579000523927 4.78432559967041\n",
      "0.0002234489508253981 4.830988883972168\n",
      "0.0002442065036343149 4.171138763427734\n",
      "0.0002668923536987048 4.568757057189941\n",
      "0.0002916856324576008 4.394467353820801\n",
      "0.00031878211197552 5.047836780548096\n",
      "0.000348395750792918 5.254640102386475\n",
      "0.0003807603833802382 4.774016857147217\n",
      "0.00041613156653577953 4.725322723388672\n",
      "0.0004547885973068628 4.806528568267822\n",
      "0.000497036718368156 5.009194374084473\n",
      "0.0005432095282712088 5.154918193817139\n",
      "0.0005936716155969495 4.6115593910217285\n",
      "0.0006488214378108738 5.028186798095703\n",
      "0.0007090944675528675 4.7621612548828125\n",
      "0.0007749666312053197 4.5255584716796875\n",
      "0.0008469580668910596 4.472836017608643\n",
      "0.0009256372315749285 4.529234409332275\n",
      "0.0010116253896993754 4.72245454788208\n",
      "0.0011056015187971314 4.7901458740234375\n",
      "0.0012083076708165371 4.827102184295654\n",
      "0.0013205548314934833 4.679256439208984\n",
      "0.0014432293240365934 4.002681732177734\n",
      "0.0015772998076902661 4.544960021972656\n",
      "0.0017238249264374492 4.786757946014404\n",
      "0.0018839616682376494 4.291604518890381\n",
      "0.002058974500806174 4.872935771942139\n",
      "0.0022502453560723215 4.356709003448486\n",
      "0.002459284542155542 4.20601224899292\n",
      "0.0026877426690224506 4.981508731842041\n",
      "0.002937423681991749 4.531796932220459\n",
      "0.003210299106001912 4.496154308319092\n",
      "0.0035085236131168433 4.505562782287598\n",
      "0.003834452036193271 4.507040500640869\n",
      "0.004190657963052755 5.271383285522461\n",
      "0.004579954057981153 4.702674865722656\n",
      "0.0050054142710176525 3.9111557006835938\n",
      "0.005470398110401807 4.393452167510986\n",
      "0.00597857716983804 4.042508602142334\n",
      "0.006533964120041574 4.0774030685424805\n",
      "0.007140944393488058 2.270380735397339\n",
      "0.007804310812555254 1.9231404066085815\n",
      "0.008529301434486616 1.476881980895996\n",
      "0.00932164091200723 2.093632459640503\n",
      "0.010187585696182765 0.7143656611442566\n",
      "0.011133973438451109 1.8333845138549805\n",
      "0.012168276981913778 0.5236473083496094\n",
      "0.01329866336821178 1.2522825002670288\n",
      "0.014534058325914513 1.3528499603271484\n",
      "0.015884216749633348 1.279292345046997\n",
      "0.017359799726375243 1.094985008239746\n",
      "0.018972458717349993 0.762380063533783\n",
      "0.020734927559945344 0.7317734956741333\n",
      "0.02266112301633371 0.980624794960022\n",
      "0.024766254662659793 1.3622350692749023\n",
      "0.027066944986513432 1.3737062215805054\n",
      "0.029581360640998283 1.0977007150650024\n",
      "0.0323293558918014 1.5508484840393066\n",
      "0.035332629389946885 1.4459179639816284\n",
      "0.03861489550813867 1.8538540601730347\n",
      "0.042202071593594175 0.66502845287323\n",
      "0.04612248261594992 1.0054163932800293\n",
      "0.05040708482617477 0.7808018922805786\n",
      "0.055089710192540726 2.1071579456329346\n",
      "0.06020733354376036 3.154726266860962\n",
      "0.06580036452869985 1.183375358581543\n",
      "0.07191296669803261 2.568232297897339\n",
      "0.07859340622735805 2.1115195751190186\n",
      "0.08589443303536398 1.0269020795822144\n",
      "0.09387369730640871 1.9282293319702148\n",
      "0.10259420470645761 2.3938097953796387\n",
      "0.1121248138868389 1.2194557189941406\n",
      "0.12254078020419554 2.1836111545562744\n",
      "0.13392434994994046 1.0559383630752563\n",
      "0.1463654097813557 1.0539263486862183\n",
      "0.15996219648235593 1.8386682271957397\n",
      "0.17482207265831248 1.2120966911315918\n",
      "0.191062374489959 0.9182718396186829\n",
      "0.20881133824039233 1.0095431804656982\n",
      "0.22820911283102988 1.0092153549194336\n",
      "0.24940886648199986 1.2588411569595337\n",
      "0.2725779961551911 0.6878239512443542\n",
      "0.2978994493499356 2.343839168548584\n",
      "0.3255731686884542 1.8519150018692017\n",
      "0.35581767069776415 2.037156820297241\n",
      "0.388871771254387 2.0357630252838135\n",
      "0.42499647131626994 0.9284723401069641\n",
      "0.464477017831989 1.9679034948349\n",
      "0.5076251561005345 2.598345994949341\n",
      "0.5547815913667042 1.720926284790039\n",
      "0.6063186790892943 2.505709171295166\n",
      "0.6626433651249117 2.415853500366211\n",
      "0.7242003990436193 1.2559226751327515\n",
      "0.7914758459493108 0.7712538838386536\n",
      "0.8650009245347657 1.965579628944397\n",
      "0.9453562016773396 1.818955421447754\n",
      "1.033176176696546 1.263635277748108\n",
      "1.129154291471635 2.1174404621124268\n",
      "1.2340484059799288 0.6883844137191772\n",
      "1.3486867824917255 0.36003434658050537\n",
      "1.4739746256740167 2.368821859359741\n",
      "1.6109012302448271 2.357621908187866\n",
      "1.7605477926172974 1.5564097166061401\n",
      "1.9240959482156252 2.0028560161590576\n",
      "2.102837101875 1.5994871854782104\n",
      "2.2981826250000004 1.494787573814392\n",
      "2.5116750000000003 0.9811767935752869\n",
      "2.745 1.2374318838119507\n",
      "3.0 1.4611338376998901\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7f455717535c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m                         pin_memory=True)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_range_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;31m# [0.0007, 0.01]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7f455717535c>\u001b[0m in \u001b[0;36mlr_range_test\u001b[0;34m(loader, model, dataset, device, min_lr, iters)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miter_id\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mlr_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0miter_id\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# def lr_exp_list(min_lr=0.0001, max_lr=3, iters=300, mode='exp'):\n",
    "#     assert mode in ['exp', 'linear']\n",
    "#     if mode=='exp':\n",
    "#         lr_list = list(reversed([max_lr*0.915**i for i in range(iters)]))\n",
    "#     else:\n",
    "#         step = (lr_max-lr_min)/iters\n",
    "#         lr_list = [step*i for i in range(1,iters+1)]\n",
    "#     return lr_list\n",
    "\n",
    "# def lr_range_test(loader, model, dataset, device, min_lr, iters=300):\n",
    "#     '''\n",
    "#     try to find best lr range;\n",
    "#     return batch_loss_list;\n",
    "#     '''\n",
    "#     batch_loss_list = []\n",
    "#     model = model.to(device)\n",
    "#     running_loss = 0.\n",
    "#     model.train()\n",
    "#     iter_id = 0 \n",
    "#     lr_list = lr_exp_list(min_lr=min_lr, iters=iters)\n",
    "#     vis = Visdom(env = 'lr_range_test1')\n",
    "#     for imgs, masks, H, W in progress_bar(loader):\n",
    "#         if iter_id <= iters:\n",
    "#             lr_tmp = lr_list[iter_id]\n",
    "#             iter_id += 1\n",
    "#             optimizer = torch.optim.SGD(params = model.parameters(), lr=lr_tmp)\n",
    "#             optimizer.zero_grad()\n",
    "#             imgs, masks = imgs.to(device), masks.to(device)\n",
    "#             with torch.set_grad_enabled(True):\n",
    "#                 logits, cls_logits = model(imgs) # [bs, cls, H, W] [bs, cls]\n",
    "#     #             loss1 = multi_class_entropy(logits, masks.squeeze().int())\n",
    "#                 loss1 = FocalLoss2D_2(num_class=num_class, device=device)(logits, masks.squeeze().int())\n",
    "#     #             loss2 = DiceLoss2D(cls_num=11, device=device)(logits, masks.squeeze().int())\n",
    "#     #             loss2 = lovasz_softmax(logits.squeeze(), masks.squeeze().int(), per_image=False)\n",
    "#     #             loss3 = torch.nn.CrossEntropyLoss()(cls_logits, cls)\n",
    "#                 loss = loss1 \n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#             print(lr_tmp, loss.item())\n",
    "#             batch_loss_list.append([lr_tmp, loss.item()])\n",
    "#             vis.line(X=[lr_tmp], Y=[[loss.item()]], opts=dict(markers=True, showlegend=True), win='loss', update='append')\n",
    "#         else:\n",
    "#             break\n",
    "#     return batch_loss_list\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     from torch.utils.data import DataLoader\n",
    "#     from torch.utils.data.sampler import RandomSampler\n",
    "#     from loss import multi_class_entropy, lovasz_softmax, FocalLoss2d, DiceLoss2D, FocalLoss2D_2\n",
    "#     from data2 import Jiu2Data\n",
    "#     from model import *\n",
    "#     from loss import multi_class_entropy, lovasz_softmax\n",
    "#     from fastprogress.fastprogress import master_bar, progress_bar\n",
    "#     from visdom import Visdom\n",
    "\n",
    "#     num_class = 24\n",
    "#     batch_size = 20\n",
    "#     model = Unet_qb(num_class=num_class, HyperColumn=True)\n",
    "\n",
    "#     device = 'cuda'\n",
    "#     fold_id = 1\n",
    "\n",
    "#     train_data = Jiu2Data(fold_id=fold_id, mode='train')\n",
    "#     train_loader = DataLoader(\n",
    "#                         train_data,\n",
    "#                         shuffle=RandomSampler(train_data),\n",
    "#                         batch_size=batch_size,\n",
    "#                         num_workers=8,\n",
    "#                         pin_memory=True)\n",
    "\n",
    "#     res = lr_range_test(train_loader, model, train_data, device, min_lr=0.0001, iters=170)\n",
    "#     # [0.005, 0.01]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

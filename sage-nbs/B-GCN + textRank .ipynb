{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n'dear customer txn on indusind bank credit card no xx5007 for \\ninr 2741 on 26/08/18 18:20 at rajpath motors is approved.pls call \\n    18602677777 for query.click on http://bit.ly/2b8nsnl to update \\n        your aadhaar number, ignore if already done.',\\n           \\n'your a/c no. xxxxxxxxxx9359 is credited by rs.5,500.00 on 18/09/18 \\nby a/c linked to mobile 9xxxxxx9359 (imps ref no 826119422613).'\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于baseline 实验，1300多个模版，无法利用倍化方法提升测试集准确率，(倍化只不过让过拟合来的更早一些) 得出必然是一个少样本半监督问题；\n",
    "# 因此实验 GCN -- 它是一个半监督结构 同时 它可以利用邻居节点信息；\n",
    "\n",
    "# bug结果： 构图相似度（对称归一拉普拉斯完全忽略邻居） nx.norm_laplacian 有问题；\n",
    "# 修正： 自定义 norm laplacian fun\n",
    "# 结果： 测试集 18分类 见下面结果图；\n",
    "\n",
    "# insights： 得到的对称归一拉普拉斯矩阵 给出自身节点过量权重-暗示局部簇稀疏性； \n",
    "# 进一步猜想：\n",
    "# 以上基于相似度的构图； 其相似度基于 sms 的tf-idf； \n",
    "\n",
    "'''\n",
    "'dear customer txn on indusind bank credit card no xx5007 for \n",
    "inr 2741 on 26/08/18 18:20 at rajpath motors is approved.pls call \n",
    "    18602677777 for query.click on http://bit.ly/2b8nsnl to update \n",
    "        your aadhaar number, ignore if already done.',\n",
    "           \n",
    "'your a/c no. xxxxxxxxxx9359 is credited by rs.5,500.00 on 18/09/18 \n",
    "by a/c linked to mobile 9xxxxxx9359 (imps ref no 826119422613).'\n",
    "'''\n",
    "\n",
    "# 这两个例子都是低tf-idf相似度，然而本应该高相似度；\n",
    "# 而实际上应当基于核心词汇（credit, debited, transaction, balance .. ）\n",
    "# 我可以通过textRank 构建这样的核心词汇表， 然后重新编码 sms 向量 BOW；\n",
    "# no no no, 仍用tf-idf 构建文本编码，但是构图相似度用 textRank tf-idf构建；\n",
    "\n",
    "# bug结果： normlized laplacian 有问题， normadj@X 输出nan ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import community # !pip install python-louvain\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_similarity(sms, templates):\n",
    "    '''计算一条新sms 与 每个template 相似度;'''\n",
    "    def cos_sim(a, b):\n",
    "        return dot(a, b) / (norm(a) * norm(b))\n",
    "    return [cos_sim(i, sms) for i in templates]\n",
    "\n",
    "\n",
    "def tfIdfVector(corpus):\n",
    "    '''\n",
    "    corpus is a list of sentences:\n",
    "    ['This is an example', 'hello world', ...]\n",
    "    '''\n",
    "    vectorizer = CountVectorizer()\n",
    "    transformer = TfidfTransformer()\n",
    "    x = vectorizer.fit_transform(corpus)\n",
    "    tfidf = transformer.fit_transform(x)\n",
    "    return tfidf.toarray()\n",
    "\n",
    "def normalise_adj_matrix(A):\n",
    "    '''\n",
    "    normalized laplacian matrix;\n",
    "    '''\n",
    "    num_node = A.shape[0]\n",
    "    A_hat = A + np.eye(num_node) \n",
    "    D_isqrtm = np.diag(np.power(A_hat.sum(axis = 1), -0.5))\n",
    "    return D_isqrtm.dot(A_hat).dot(D_isqrtm)\n",
    "\n",
    "def get_pr(Res, cls):\n",
    "    #某类 正确识别数量/该类 总识别数量\n",
    "    tmp  = Res[Res.true == cls]\n",
    "    a = sum(tmp.true.values == tmp.pred.values)\n",
    "    b = Res[Res.pred == cls].shape[0]\n",
    "    pr = a/(b+1e-7)\n",
    "    return pr\n",
    "\n",
    "def get_rc(Res, cls):\n",
    "    #某类 正确识别数量/该类 总数量\n",
    "    tmp  = Res[Res.true == cls]\n",
    "    support = tmp.shape[0]\n",
    "    a = sum(tmp.true.values == tmp.pred.values)\n",
    "    b = Res[Res.true == cls].shape[0]\n",
    "    rc = a/(1e-7+b)\n",
    "    return rc,support\n",
    "\n",
    "def get_f1(pr, rc):\n",
    "    # f1 = (2*pr*rc)/(pr+rc)\n",
    "    f1 = (2*pr*rc)/(pr+rc+1e-7)\n",
    "    return f1\n",
    "\n",
    "def evaluate(Res, cls):\n",
    "    pr = get_pr(Res, cls)\n",
    "    rc, support = get_rc(Res, cls)\n",
    "    f1 = get_f1(pr, rc)\n",
    "    return [cls, pr, rc, f1, support]\n",
    "\n",
    "def Final_evalu(z):\n",
    "    Res = pd.DataFrame(columns=['true', 'pred'])\n",
    "    true, pred = z.label.tolist(), z.pred.tolist()\n",
    "    Res['true'] = true\n",
    "    Res['pred'] = pred\n",
    "    entitys = Res.true.unique()\n",
    "    records = []\n",
    "    for i in entitys:\n",
    "        tmp = evaluate(Res, i)\n",
    "        records.append(tmp)\n",
    "    record = pd.DataFrame.from_records(records)\n",
    "    record.columns =['cls','精确率','召回率', 'F1', 'support']\n",
    "    record = record.set_index('cls')\n",
    "    record = record.sort_index()   \n",
    "    return record\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def evalu(text, Y_hat, label, labels2idx):\n",
    "    preds = Y_hat.eval().argmax(axis=-1)\n",
    "    scores = np.array([softmax(i) for i in Y_hat.eval()])\n",
    "    score = scores.max(axis=-1)\n",
    "    idx2label = {i:j for j,i in labels2idx.items()}\n",
    "    pred = [[idx2label[i] for i in preds]]\n",
    "    df = pd.DataFrame()\n",
    "    df['text'] = text\n",
    "    df['pred'] = pred\n",
    "    df['label'] = label\n",
    "    df['score'] =score\n",
    "    return df\n",
    "\n",
    "def evalu2(text, Y_hat, label, labels2idx):\n",
    "    scores = np.array([softmax(i) for i in Y_hat.eval()])\n",
    "    sort_score = scores.argsort(axis=-1)\n",
    "    idx2label = {i:j for j,i in labels2idx.items()}\n",
    "    sort_labels = [[idx2label[j] for j in i][:3] for i in sort_score]\n",
    "    sort_scores = [i[np.argsort(-i)][:3] for i in scores]\n",
    "    preds = Y_hat.eval().argmax(axis=-1)\n",
    "    idx2label = {i:j for j,i in labels2idx.items()}\n",
    "    preds = [idx2label[i] for i in preds]\n",
    "    df = pd.DataFrame()\n",
    "    df['text'] = text\n",
    "    df['pred2'] = sort_labels\n",
    "    df['label'] = label\n",
    "    df['score'] = sort_scores\n",
    "    df['pred'] = preds\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v1: 纯GCN nx 的归一化拉普拉斯矩阵；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear customer txn on indusind bank credit card...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>your indusind bank a/c no.100***942932 has bee...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>your a/c no. xxxxxxxxxx9359 is credited by rs....</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your indusind bank a/c no.159***479359 has bee...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your a/c no. xxxxxxxxxx2932 is debited for rs....</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dear customer, your account no 100***942932 ha...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dear customer, thank you for your internet pay...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dear customer, statement for your indusind ban...</td>\n",
       "      <td>信用卡＿还款提醒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>your curr loan emi rs.2865 for ahb00485s due o...</td>\n",
       "      <td>贷后提醒＿逾期催收</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>your a/c no. xxxxxx2932 is credited for rs. 30...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dear customer, as per the last statement gener...</td>\n",
       "      <td>信用卡＿逾期警告</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dear customer, your account no 159***479359 ha...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ur curr loan emi rs. 2789.00 for awp04070h due...</td>\n",
       "      <td>贷后提醒＿到期提醒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dear customer, the payment on your indusind ba...</td>\n",
       "      <td>信用卡＿逾期警告</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>your indusind bank a/c no.200***439985 has bee...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>your indusind bank a/c no. 200***439985 has be...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dear customer, your savings account a/c 159***...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dear customer, txn on indusind bank credit car...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dear customer, the 03-sep-2018 statement for y...</td>\n",
       "      <td>信用卡＿还款提醒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bal of inr 1,059.55 on 03/09/18 05:11 am in a/...</td>\n",
       "      <td>交易流水＿余额</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sorry! the balance available in your indusind ...</td>\n",
       "      <td>账号异常＿余额不足</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dear cust, thanks for your cash payment of rs....</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>indusind bank a/c no.200***439985 has been cre...</td>\n",
       "      <td>账户账号＿自己</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>your bank a/c no.159***479359 has been debited...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>your fund transfer for rs. 8,000.00 on 12/09/1...</td>\n",
       "      <td>账号异常＿扣款失败</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>the balance in your a/c 10xxxxxxx2569 has been...</td>\n",
       "      <td>账号异常＿余额不足</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>your one time password for pin generation on i...</td>\n",
       "      <td>sms_other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>indusind bank a/c no.200***439985 has been deb...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the balance in your a/c 10xxxxxxx2569 has been...</td>\n",
       "      <td>账号异常＿余额不足</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cheque no. 617505 issued by you for rs.100,000...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>your a/c no. xxxxxxx3825 is credited by rs.10....</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>lpg subsidy of rs. 257.74 has been credited in...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>your a/c xxxxxxx5138 is debited by rs. 5,000 b...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>neft transfer of rs. 18000 to canara bank will...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>your a/c no **00....416 is debited for rs.1000...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>dear customer, your request for imps payment o...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>your a/c xxxxxxxxxxxx538 in bangalore-chikkaba...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>your a/c xxxxxxxxxxxx731 in aali debited inr 4...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>an amount of rs. 149 has been debited from you...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>your a/c xxxx8575 debited rs.149000.00 on 19-0...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>returned, chq:940102 for rs.15431.00 fvg capit...</td>\n",
       "      <td>sms_other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>inr 500.00 debited to a/c **41...716 from atm ...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>your a/c no. xxxxxxxx3263 is credited for rs.5...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>your a/c no. **00....652 is credited for rs.90...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>inward clg cheque: 023028 for rs.135000.00 fvg...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>your request for the payment rs. 4500 has been...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>dear customer, your account **50...660 has bee...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>due, rs.2217 towards your loan a/c x..x3012 in...</td>\n",
       "      <td>贷后提醒＿到期提醒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>your a/c ...162 in credited inr 21000.00 on 21...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>your a/c no. xxxxxxxx2150 is credited by rs.3,...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>your a/c no. xxxxxxxx0595 is debited for rs. 2...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>you have done a transaction from your iob inte...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>your avl balance acct : 0193xxxxxxxxx69 is rs ...</td>\n",
       "      <td>交易流水＿余额</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>you have done a tax/bill payment through iob i...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>your iob cheque no. ***8793 for rs. 3,600.00 i...</td>\n",
       "      <td>信用卡＿还款提醒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>dear customer,your loan a/c 1441***121 with io...</td>\n",
       "      <td>贷后提醒＿逾期催收</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>mandate(ref no: ioba02649404) issued to homecr...</td>\n",
       "      <td>账号异常＿扣款失败</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>mandate(ref no: ioba02649404) issued to homecr...</td>\n",
       "      <td>sms_other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>you have done a transaction through iob intern...</td>\n",
       "      <td>交易流水＿转账</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>dear customer,in order to serve you better, ax...</td>\n",
       "      <td>交易流水＿余额</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sms      label\n",
       "0     dear customer txn on indusind bank credit card...    交易流水＿转账\n",
       "1     your indusind bank a/c no.100***942932 has bee...    交易流水＿转账\n",
       "2     your a/c no. xxxxxxxxxx9359 is credited by rs....    交易流水＿转账\n",
       "3     your indusind bank a/c no.159***479359 has bee...    交易流水＿转账\n",
       "4     your a/c no. xxxxxxxxxx2932 is debited for rs....    交易流水＿转账\n",
       "5     dear customer, your account no 100***942932 ha...    交易流水＿转账\n",
       "6     dear customer, thank you for your internet pay...    交易流水＿转账\n",
       "7     dear customer, statement for your indusind ban...   信用卡＿还款提醒\n",
       "8     your curr loan emi rs.2865 for ahb00485s due o...  贷后提醒＿逾期催收\n",
       "9     your a/c no. xxxxxx2932 is credited for rs. 30...    交易流水＿转账\n",
       "10    dear customer, as per the last statement gener...   信用卡＿逾期警告\n",
       "11    dear customer, your account no 159***479359 ha...    交易流水＿转账\n",
       "12    ur curr loan emi rs. 2789.00 for awp04070h due...  贷后提醒＿到期提醒\n",
       "13    dear customer, the payment on your indusind ba...   信用卡＿逾期警告\n",
       "14    your indusind bank a/c no.200***439985 has bee...    交易流水＿转账\n",
       "15    your indusind bank a/c no. 200***439985 has be...    交易流水＿转账\n",
       "16    dear customer, your savings account a/c 159***...    交易流水＿转账\n",
       "17    dear customer, txn on indusind bank credit car...    交易流水＿转账\n",
       "18    dear customer, the 03-sep-2018 statement for y...   信用卡＿还款提醒\n",
       "19    bal of inr 1,059.55 on 03/09/18 05:11 am in a/...    交易流水＿余额\n",
       "20    sorry! the balance available in your indusind ...  账号异常＿余额不足\n",
       "21    dear cust, thanks for your cash payment of rs....    交易流水＿转账\n",
       "22    indusind bank a/c no.200***439985 has been cre...    账户账号＿自己\n",
       "23    your bank a/c no.159***479359 has been debited...    交易流水＿转账\n",
       "24    your fund transfer for rs. 8,000.00 on 12/09/1...  账号异常＿扣款失败\n",
       "25    the balance in your a/c 10xxxxxxx2569 has been...  账号异常＿余额不足\n",
       "26    your one time password for pin generation on i...  sms_other\n",
       "27    indusind bank a/c no.200***439985 has been deb...    交易流水＿转账\n",
       "28    the balance in your a/c 10xxxxxxx2569 has been...  账号异常＿余额不足\n",
       "29    cheque no. 617505 issued by you for rs.100,000...    交易流水＿转账\n",
       "...                                                 ...        ...\n",
       "1166  your a/c no. xxxxxxx3825 is credited by rs.10....    交易流水＿转账\n",
       "1167  lpg subsidy of rs. 257.74 has been credited in...    交易流水＿转账\n",
       "1168  your a/c xxxxxxx5138 is debited by rs. 5,000 b...    交易流水＿转账\n",
       "1169  neft transfer of rs. 18000 to canara bank will...    交易流水＿转账\n",
       "1170  your a/c no **00....416 is debited for rs.1000...    交易流水＿转账\n",
       "1171  dear customer, your request for imps payment o...    交易流水＿转账\n",
       "1172  your a/c xxxxxxxxxxxx538 in bangalore-chikkaba...    交易流水＿转账\n",
       "1173  your a/c xxxxxxxxxxxx731 in aali debited inr 4...    交易流水＿转账\n",
       "1174  an amount of rs. 149 has been debited from you...    交易流水＿转账\n",
       "1175  your a/c xxxx8575 debited rs.149000.00 on 19-0...    交易流水＿转账\n",
       "1176  returned, chq:940102 for rs.15431.00 fvg capit...  sms_other\n",
       "1177  inr 500.00 debited to a/c **41...716 from atm ...    交易流水＿转账\n",
       "1178  your a/c no. xxxxxxxx3263 is credited for rs.5...    交易流水＿转账\n",
       "1179  your a/c no. **00....652 is credited for rs.90...    交易流水＿转账\n",
       "1180  inward clg cheque: 023028 for rs.135000.00 fvg...    交易流水＿转账\n",
       "1181  your request for the payment rs. 4500 has been...    交易流水＿转账\n",
       "1182  dear customer, your account **50...660 has bee...    交易流水＿转账\n",
       "1183  due, rs.2217 towards your loan a/c x..x3012 in...  贷后提醒＿到期提醒\n",
       "1184  your a/c ...162 in credited inr 21000.00 on 21...    交易流水＿转账\n",
       "1185  your a/c no. xxxxxxxx2150 is credited by rs.3,...    交易流水＿转账\n",
       "1186  your a/c no. xxxxxxxx0595 is debited for rs. 2...    交易流水＿转账\n",
       "1187  you have done a transaction from your iob inte...    交易流水＿转账\n",
       "1188  your avl balance acct : 0193xxxxxxxxx69 is rs ...    交易流水＿余额\n",
       "1189  you have done a tax/bill payment through iob i...    交易流水＿转账\n",
       "1190  your iob cheque no. ***8793 for rs. 3,600.00 i...   信用卡＿还款提醒\n",
       "1191  dear customer,your loan a/c 1441***121 with io...  贷后提醒＿逾期催收\n",
       "1192  mandate(ref no: ioba02649404) issued to homecr...  账号异常＿扣款失败\n",
       "1193  mandate(ref no: ioba02649404) issued to homecr...  sms_other\n",
       "1194  you have done a transaction through iob intern...    交易流水＿转账\n",
       "1195  dear customer,in order to serve you better, ax...    交易流水＿余额\n",
       "\n",
       "[1196 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm_templates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_templates_df = pd.read_csv('gsm_templates_df.csv')\n",
    "corpus, labels = gsm_templates_df.sms.tolist(), gsm_templates_df.label.tolist()\n",
    "\n",
    "all_tfidf = tfIdfVector(corpus)\n",
    "num_sms = 100\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "adj_mat = cosine_similarity(all_tfidf)\n",
    "# adj_mat = np.where(adj_mat>0.5, 1, 0)\n",
    "G2 = nx.from_numpy_matrix(adj_mat)\n",
    "# norm_adj_mat = nx.normalized_laplacian_matrix(G2).toarray()\n",
    "norm_adj  = normalise_adj_matrix(adj_mat)\n",
    "for i in range(len(corpus)):\n",
    "    G2.node[i]['vec'] =  all_tfidf[i]\n",
    "    G2.node[i]['text'] = corpus[i]\n",
    "    G2.node[i]['label'] = labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2idx = {j:i for i,j in enumerate(set(labels))}\n",
    "labels_new = [labels2idx[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-374b81114532>:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/tigergraph/test1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "X = np.array([G2.node[i]['vec'] for i in list(G2.nodes)])\n",
    "Y = np.array(labels_new)\n",
    "num_class = len(set(Y))\n",
    "num_new_sms = 100\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "X = tf.constant(X)\n",
    "A = tf.constant(norm_adj_mat, dtype='float64')\n",
    "Y = tf.constant(Y)\n",
    "masks = np.ones(len(G2.nodes))\n",
    "masks[-num_new_sms:] = 0\n",
    "masks = tf.constant(masks)\n",
    "\n",
    "Z = tf.layers.dense(tf.matmul(A, X), units=2, use_bias=False, activation=tf.nn.tanh)\n",
    "Y_hat = tf.layers.dense(tf.matmul(A, Z), units=num_class, use_bias=False, activation=None)\n",
    "tmp_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=Y_hat, labels=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ids = range(len(labels_new))[-num_new_sms:]\n",
    "\n",
    "loss = tf.reduce_mean(tmp_loss * masks)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(0.01)\n",
    "\n",
    "train = opt.minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for I in range(10000):\n",
    "    _, loss_val = sess.run([train, loss])\n",
    "    if I % 100 == 0:\n",
    "        Z_val = Z.eval()\n",
    "        df  = evalu2(corpus, Y_hat, labels, labels2idx)\n",
    "        res = Final_evalu(df.iloc[-100:])\n",
    "        print('####### batch i:{} #######'.format(I))\n",
    "        print('loss = %f' % loss_val)\n",
    "        mean_tra_f1 = np.mean([i for i in Final_evalu(df.iloc[:-100]).F1.values if i != 0])\n",
    "        print('mean f1 of train data:{}'.format(mean_tra_f1))\n",
    "        \n",
    "        mean_f1 = np.mean([i for i in Final_evalu(df.iloc[-100:]).F1.values if i != 0])\n",
    "        print('mean f1 of test 100:{}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v1: 纯GCN 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>精确率</th>\n",
       "      <th>召回率</th>\n",
       "      <th>F1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms_other</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>交易流水＿余额</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>交易流水＿转账</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>信用卡＿还款提醒</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>信用卡＿逾期警告</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>账号异常＿余额不足</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>账号异常＿卡号冻结</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>账号异常＿扣款失败</th>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>贷前申请＿审核拒绝</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>贷前申请＿申请交互</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>贷后提醒＿到期提醒</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>贷后提醒＿逾期催收</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                精确率       召回率        F1  support\n",
       "cls                                             \n",
       "sms_other  0.000000  0.000000  0.000000        3\n",
       "交易流水＿余额    0.000000  0.000000  0.000000        3\n",
       "交易流水＿转账    0.000000  0.000000  0.000000       57\n",
       "信用卡＿还款提醒   0.500000  0.176471  0.260870       17\n",
       "信用卡＿逾期警告   0.000000  0.000000  0.000000        5\n",
       "账号异常＿余额不足  0.000000  0.000000  0.000000        1\n",
       "账号异常＿卡号冻结  0.000000  0.000000  0.000000        1\n",
       "账号异常＿扣款失败  0.044444  0.500000  0.081633        4\n",
       "贷前申请＿审核拒绝  0.000000  0.000000  0.000000        2\n",
       "贷前申请＿申请交互  0.000000  0.000000  0.000000        1\n",
       "贷后提醒＿到期提醒  0.000000  0.000000  0.000000        4\n",
       "贷后提醒＿逾期催收  0.000000  0.000000  0.000000        2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_evalu(df.iloc[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v1: 纯GCN 结果 归一化拉普拉斯自己写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_adj_matrix(A):\n",
    "    '''\n",
    "    N = D^{-1/2} L D^{-1/2}\n",
    "    '''\n",
    "    num_node = A.shape[0]\n",
    "#     A_hat = A + np.eye(num_node) \n",
    "    A_hat = A\n",
    "    D_isqrtm = np.diag(np.power(A_hat.sum(axis=1), -0.5))\n",
    "    print(D_isqrtm)\n",
    "    return D_isqrtm.dot(A_hat).dot(D_isqrtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11104316 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.11254343 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.10451165 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.14580781 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.11851082 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.12281465]]\n"
     ]
    }
   ],
   "source": [
    "gsm_templates_df = pd.read_csv('gsm_templates_df.csv')\n",
    "corpus, labels = gsm_templates_df.sms.tolist(), gsm_templates_df.label.tolist()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "all_tfidf = tfIdfVector(corpus)\n",
    "num_sms = 100\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "adj_mat = cosine_similarity(all_tfidf)\n",
    "# adj_mat = np.where(adj_mat>0.5, 1, 0)\n",
    "G2 = nx.from_numpy_matrix(adj_mat)\n",
    "# norm_adj_mat = nx.normalized_laplacian_matrix(G2).toarray()\n",
    "norm_adj  = normalise_adj_matrix(adj_mat)\n",
    "for i in range(len(corpus)):\n",
    "    G2.node[i]['vec'] =  all_tfidf[i]\n",
    "    G2.node[i]['text'] = corpus[i]\n",
    "    G2.node[i]['label'] = labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2idx = {j:i for i,j in enumerate(set(labels))}\n",
    "labels_new = [labels2idx[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([G2.node[i]['vec'] for i in list(G2.nodes)])\n",
    "Y = np.array(labels_new)\n",
    "num_class = len(set(Y))\n",
    "num_new_sms = 100\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "X = tf.constant(X)\n",
    "A = tf.constant(norm_adj, dtype='float64')\n",
    "Y = tf.constant(Y)\n",
    "masks = np.ones(len(G2.nodes))\n",
    "masks[-num_new_sms:] = 0\n",
    "masks = tf.constant(masks)\n",
    "\n",
    "Z = tf.layers.dense(tf.matmul(A, X), units=2, use_bias=False, activation=tf.nn.tanh)\n",
    "Y_hat = tf.layers.dense(tf.matmul(A, Z), units=num_class, use_bias=False, activation=None)\n",
    "tmp_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=Y_hat, labels=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### batch i:0 #######\n",
      "loss = 2.648993\n",
      "mean f1 of train data:nan\n",
      "mean f1 of test 100:nan\n",
      "####### batch i:100 #######\n",
      "loss = 1.423873\n",
      "mean f1 of train data:0.7788300359244914\n",
      "mean f1 of test 100:0.726114602507204\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cef0c1a22028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mI\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mZ_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mask_ids = range(len(labels_new))[-num_new_sms:]\n",
    "\n",
    "loss = tf.reduce_mean(tmp_loss * masks)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(0.01)\n",
    "\n",
    "train = opt.minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for I in range(10000):\n",
    "    _, loss_val = sess.run([train, loss])\n",
    "    if I % 100 == 0:\n",
    "        Z_val = Z.eval()\n",
    "        df  = evalu2(corpus, Y_hat, labels, labels2idx)\n",
    "        res = Final_evalu(df.iloc[-100:])\n",
    "        print('####### batch i:{} #######'.format(I))\n",
    "        print('loss = %f' % loss_val)\n",
    "        mean_tra_f1 = np.mean([i for i in Final_evalu(df.iloc[:-100]).F1.values if i != 0])\n",
    "        print('mean f1 of train data:{}'.format(mean_tra_f1))\n",
    "        \n",
    "        mean_f1 = np.mean([i for i in Final_evalu(df.iloc[-100:]).F1.values if i != 0])\n",
    "        print('mean f1 of test 100:{}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>精确率</th>\n",
       "      <th>召回率</th>\n",
       "      <th>F1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms_other</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>交易流水＿余额</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>交易流水＿转账</th>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>信用卡＿还款提醒</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>信用卡＿逾期警告</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>账号异常＿余额不足</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>账号异常＿卡号冻结</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>账号异常＿扣款失败</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>贷前申请＿审核拒绝</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>贷前申请＿申请交互</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>贷后提醒＿到期提醒</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>贷后提醒＿逾期催收</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                精确率       召回率        F1  support\n",
       "cls                                             \n",
       "sms_other  0.000000  0.000000  0.000000        3\n",
       "交易流水＿余额    1.000000  0.333333  0.500000        3\n",
       "交易流水＿转账    0.808824  0.964912  0.880000       57\n",
       "信用卡＿还款提醒   0.666667  0.588235  0.625000       17\n",
       "信用卡＿逾期警告   1.000000  0.200000  0.333333        5\n",
       "账号异常＿余额不足  0.250000  1.000000  0.400000        1\n",
       "账号异常＿卡号冻结  0.000000  0.000000  0.000000        1\n",
       "账号异常＿扣款失败  0.000000  0.000000  0.000000        4\n",
       "贷前申请＿审核拒绝  0.000000  0.000000  0.000000        2\n",
       "贷前申请＿申请交互  0.250000  1.000000  0.400000        1\n",
       "贷后提醒＿到期提醒  0.000000  0.000000  0.000000        4\n",
       "贷后提醒＿逾期催收  0.142857  0.500000  0.222222        2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_evalu(df.iloc[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2-textRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rollWindPairs(filtered_sents, windowSize=5):\n",
    "    '''\n",
    "    filtered_sents: [['token1','token2', ..], [. , . ,], ..]\n",
    "    '''\n",
    "    assert isinstance(filtered_sents[0], list)\n",
    "    token_pairs = []\n",
    "    for sent in filtered_sents:\n",
    "        for i, word in enumerate(sent):\n",
    "            for j in range(i + 1, i + window_size):\n",
    "                if j >= len(sent):\n",
    "                    break\n",
    "                pair = (word, sent[j])\n",
    "                if pair not in token_pairs:\n",
    "                    token_pairs.append(pair)\n",
    "    return token_pairs\n",
    "\n",
    "def filter_sents(sents, candidate_pos, stop_words):\n",
    "    '''\n",
    "    sents:['sms1', 'sms2', ...]\n",
    "    1. stopword filter ; \n",
    "    2. postag filter ; \n",
    "    return: [['token1','token2', ..], [. , . ,], ..]\n",
    "    '''\n",
    "    sents_new = []\n",
    "    for i in sents:\n",
    "        token_lis = i.split()\n",
    "        token_lis = nltk.pos_tag(token_lis)\n",
    "        sent = [i[0].lower() for i in token_lis \n",
    "                if (i[1] in candidate_pos) and (i[0] not in stop_words)]\n",
    "        sents_new.append(sent)\n",
    "    return sents_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_templates_df = pd.read_csv('gsm_templates_df.csv')\n",
    "corpus, labels = gsm_templates_df.sms.tolist(), gsm_templates_df.label.tolist()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "all_tfidf = tfIdfVector(corpus)\n",
    "labels2idx = {j:i for i,j in enumerate(set(labels))}\n",
    "labels_new = [labels2idx[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter processed.\n"
     ]
    }
   ],
   "source": [
    "# step 1; rankText IO:\n",
    "window_size = 3\n",
    "sents = gsm_templates_df.sms.tolist()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "cand_pos = ['NN', 'VBN', 'VBD']\n",
    "filtered_sents = filter_sents(sents, cand_pos, stop_words)\n",
    "print('filter processed.')\n",
    "pathList = rollWindPairs(filtered_sents, windowSize=4)\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(pathList)\n",
    "pr_value = nx.pagerank(G, alpha=1)\n",
    "pr_impro_value = nx.pagerank(G, alpha=0.85)\n",
    "\n",
    "# 老板词过滤文本\n",
    "BossToken = list(sorted(pr_impro_value.items(), key=lambda x: x[1], reverse=True))[:150]\n",
    "BossToken = [i[0] for i in BossToken]\n",
    "gsm_new_template = []\n",
    "for sms in gsm_templates_df.sms.tolist():\n",
    "    new_sms = [] \n",
    "    for token in sms.split():\n",
    "        if token in BossToken:\n",
    "            new_sms.append(token)\n",
    "    gsm_new_template.append(' '.join(new_sms))\n",
    "\n",
    "gsm_templates_df['new_sms'] = gsm_new_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08240205 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.08445456 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.08508444 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.13062884 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.11096296 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.13562951]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 过滤后的文本 重新向量化；\n",
    "text = gsm_templates_df.new_sms.tolist()\n",
    "vectorizer = TfidfVectorizer()\n",
    "vec_text = vectorizer.fit_transform(text).toarray()\n",
    "adj_mat = cosine_similarity(vec_text)\n",
    "# adj_mat = np.where(adj_mat > 0.5, 1, 0)\n",
    "\n",
    "def normalise_adj_matrix(A):\n",
    "    '''\n",
    "    N = D^{-1/2} L D^{-1/2}\n",
    "    '''\n",
    "    num_node = A.shape[0]\n",
    "#     A_hat = A + np.eye(num_node) \n",
    "    A_hat = A\n",
    "    D_isqrtm = np.diag(np.power(A_hat.sum(axis=1), -0.5))\n",
    "    print(D_isqrtm)\n",
    "    return D_isqrtm.dot(A_hat).dot(D_isqrtm)\n",
    "\n",
    "norm_adj  = normalise_adj_matrix(adj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_adj@all_tfidf ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(all_tfidf)\n",
    "Y = np.array(labels_new)\n",
    "num_class = len(set(Y))\n",
    "num_new_sms = 100\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "X = tf.constant(X)\n",
    "A = tf.constant(norm_adj, dtype='float64')\n",
    "Y = tf.constant(Y)\n",
    "masks = np.ones(len(all_tfidf))\n",
    "masks[-num_new_sms:] = 0\n",
    "masks = tf.constant(masks)\n",
    "\n",
    "Z = tf.layers.dense(tf.matmul(A, X), units=2, use_bias=False, activation=tf.nn.tanh)\n",
    "Y_hat = tf.layers.dense(tf.matmul(A, Z), units=num_class, use_bias=False, activation=None)\n",
    "tmp_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=Y_hat, labels=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### batch i:0 #######\n",
      "loss = nan\n",
      "mean f1 of train data:0.10051992111170938\n",
      "mean f1 of test 100:0.058252421415779444\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-cef0c1a22028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mI\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mZ_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mask_ids = range(len(labels_new))[-num_new_sms:]\n",
    "\n",
    "loss = tf.reduce_mean(tmp_loss * masks)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(0.01)\n",
    "\n",
    "train = opt.minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for I in range(10000):\n",
    "    _, loss_val = sess.run([train, loss])\n",
    "    if I % 100 == 0:\n",
    "        Z_val = Z.eval()\n",
    "        df  = evalu2(corpus, Y_hat, labels, labels2idx)\n",
    "        res = Final_evalu(df.iloc[-100:])\n",
    "        print('####### batch i:{} #######'.format(I))\n",
    "        print('loss = %f' % loss_val)\n",
    "        mean_tra_f1 = np.mean([i for i in Final_evalu(df.iloc[:-100]).F1.values if i != 0])\n",
    "        print('mean f1 of train data:{}'.format(mean_tra_f1))\n",
    "        \n",
    "        mean_f1 = np.mean([i for i in Final_evalu(df.iloc[-100:]).F1.values if i != 0])\n",
    "        print('mean f1 of test 100:{}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# personalRank: pinsage 中重要性采样技巧；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResource(csvpath):\n",
    "    '''\n",
    "    获取原始数据\n",
    "    :param csvpath: csv路径\n",
    "    :return: frame\n",
    "    '''\n",
    "    frame = pd.read_csv(csvpath)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUserGraph(frame, userID=1):\n",
    "    '''\n",
    "    获取目标用户二分图, 不计权重\n",
    "    :param frame: ratings数据\n",
    "    :param userID: 目标ID\n",
    "    :return: 二分图字典\n",
    "    '''\n",
    "    print(userID)\n",
    "    itemList = list(set(frame[frame['UserID']==userID]['MovieID']))\n",
    "    graphDict = {'i'+str(item): 1 for item in itemList}\n",
    "    return graphDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItemGraph(frame, itemID=1):\n",
    "    '''\n",
    "    获取目标物品二分图, 不计权重\n",
    "    :param frame: ratings数据\n",
    "    :param userID: 目标ID\n",
    "    :return: 二分图字典\n",
    "    '''\n",
    "    print(itemID)\n",
    "    userList = list(set(frame[frame['MovieID']==itemID]['UserID']))\n",
    "    graphDict = {'u'+str(user): 1 for user in userList}\n",
    "    return graphDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initGraph(frame):\n",
    "    '''\n",
    "    初始化二分图\n",
    "    :param frame: ratings数据集\n",
    "    :return: 二分图\n",
    "    '''\n",
    "    userList = list(set(frame['UserID']))\n",
    "    itemList = list(set(frame['MovieID']))\n",
    "    G = {'u'+str(user): getUserGraph(frame, user) for user in userList}\n",
    "    for item in itemList: \n",
    "        G['i'+str(item)] = getItemGraph(frame, item)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalRank(G, alpha, userID, iterCount=20):\n",
    "    '''\n",
    "    随机游走迭代\n",
    "    :param G: 二分图\n",
    "    :param alpha: 随机游走的概率\n",
    "    :param userID: 目标用户\n",
    "    :param iterCount: 迭代次数\n",
    "    :return: series\n",
    "    '''\n",
    "    rank = {g: 0 for g in G.keys()}\n",
    "    rank['u'+str(userID)] = 1                                       #根节点为起点选择概率为1,其他顶点为0\n",
    "    for k in range(iterCount):\n",
    "        tmp = {g: 0 for g in G.keys()}\n",
    "        for i, ri in G.items():                                     #遍历每一个顶点\n",
    "            for j, wij in ri.items():                               #遍历每个顶点连接的顶点\n",
    "                tmp[j] += alpha * rank[i] / len(ri)\n",
    "        tmp['u' + str(userID)] += 1 - alpha                         #根顶点r=1，加上1-alpha\n",
    "        rank = tmp\n",
    "    series = pd.Series(list(rank.values()), index=list(rank.keys()))\n",
    "    series = series.sort_values(ascending=False)\n",
    "    return series                                                   #返回排序后的series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(frame, series, userID, TopN=10):\n",
    "    '''\n",
    "    推荐TopN个用户没有评分的物品\n",
    "    :param frame: ratings数据\n",
    "    :param series: series\n",
    "    :param userID: 目标用户\n",
    "    :param TopN: TopN\n",
    "    :return: 推荐物品\n",
    "    '''\n",
    "    itemList = ['i'+str(i) for i in list(set(frame[frame['UserID']==userID]['MovieID']))]\n",
    "    recommendList = [{u: series[u]} for u in list(series.index) if u not in itemList and 'u' not in u]\n",
    "    return recommendList[:TopN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if isinstance(el, collections.Iterable) and not isinstance(el, (str, bytes)):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            yield el\n",
    "\n",
    "def sample_baseon_cls(df, split_rate = 0.2):\n",
    "    '''\n",
    "    train test split based on diff cls;\n",
    "    df with type: \n",
    "        ##......sms.......#......cls......##\n",
    "        ##'sms example 1.'#  交易流水＿转账 ##\n",
    "        ##'sms example 2.'#  交易流水＿转账 ##\n",
    "        ##'sms example 3.'#  交易流水＿余额 ##\n",
    "        ##'sms example 4.'#  交易流水＿其他 ##\n",
    "    '''\n",
    "    test_idx_list = []\n",
    "    classes = set(df.cls)\n",
    "    labels = df.cls\n",
    "    for i in classes:\n",
    "        sample_all_idxs = np.where(labels==i)[0]\n",
    "        num_samples = int(split_rate*len(sample_all_idxs))\n",
    "        if num_samples == 0:\n",
    "            print('Warning! MAKE SURE U HAVE SUFFICIENT SAMPLES FOR CLASS :{}'.format(i))\n",
    "        sample_idxs = np.random.choice(sample_all_idxs, size = num_samples)\n",
    "        print('class_name:{}, num_samples:{}, num_test_sample:{}'.format(i, len(sample_all_idxs), len(sample_idxs)))\n",
    "        test_idx_list.append(sample_idxs)\n",
    "    test_idx_list = list(flatten(test_idx_list))\n",
    "    df.index = range(len(df))\n",
    "    test = df[df.index.isin(test_idx_list)]\n",
    "    train = df[~df.index.isin(test_idx_list)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = sample_baseon_cls(df3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

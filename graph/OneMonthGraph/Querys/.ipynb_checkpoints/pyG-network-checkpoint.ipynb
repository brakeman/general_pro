{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "import logging\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "GRAPHSQL_URL = \"http://192.168.20.241:9000/query/OneMonthNet/\"\n",
    "\n",
    "############################ util functions ############################\n",
    "def query_graphsql_ori(query_name, para_string):\n",
    "    remaining_url = \"{}?{}\".format(query_name, para_string)\n",
    "    url=urljoin(GRAPHSQL_URL, remaining_url)\n",
    "    print('query:{}\\nparas:{}\\nrequest for url: {}'.format(query_name, para_string.split('&'), url))\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    result = requests.get(url)\n",
    "    result_json = json.loads(result.text)\n",
    "    return result_json\n",
    "\n",
    "\n",
    "def query_graphsql(query_name, para_string):\n",
    "    remaining_url = \"{}?{}\".format(query_name, para_string)\n",
    "    url=urljoin(GRAPHSQL_URL, remaining_url)\n",
    "    st = time.time()\n",
    "    print('query:{}\\nparas:{}\\nrequest for url: {}'.format(query_name, para_string.split('&'), url))\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    try:\n",
    "        result = requests.get(url)\n",
    "        result_json = json.loads(result.text)\n",
    "        if result_json['error']:\n",
    "            logging.error(result_json['message'])\n",
    "            print('run query failed')\n",
    "            return None\n",
    "        print('run query finish, use {} seconds\\n\\n'.format(time.time() - st))\n",
    "        return result_json\n",
    "    except Exception as e:\n",
    "        print('failed')\n",
    "        \n",
    "        \n",
    "def _update_max_min_date(node_name):\n",
    "    '''\n",
    "    get the max & min date for the given node type based on its history update dates;\n",
    "    para: node_name: 'Device'; check all the node_name type in gsql graph schema: OneMonthNet;\n",
    "    '''\n",
    "    query_name = 'update_max_min_date'\n",
    "    paras = 'node={}'.format(node_name)\n",
    "    return query_graphsql(query_name, paras)\n",
    "\n",
    "\n",
    "def _node_cutoff_filter(start_time, end_time, node_type):\n",
    "    '''\n",
    "    note that call _update_max_min_date before run this query;\n",
    "    select those nodes with given node_type exist between start_time and end_time;\n",
    "    paras:start_time:'2019-06-01 18:42:22'\n",
    "    paras:end_time:'2019-07-01 18:42:22'\n",
    "    paras:node_type:'User'; check all the node_name type in gsql graph schema: OneMonthNet;\n",
    "    '''\n",
    "    query_name = 'node_cutoff_filter'\n",
    "    paras = 'start_t={}&end_t={}&node={}'.format(start_time, end_time, node_type) \n",
    "    return query_graphsql(query_name, paras)\n",
    "    \n",
    "    \n",
    "########################################################################\n",
    "\n",
    "# def label_get(start_date):\n",
    "#     'old version and has been deprecated now, pls use label_get2 query;'\n",
    "#     query_name = 'label_get'\n",
    "#     paras = 'start_date={}'.format(start_date) \n",
    "#     return query_graphsql(query_name, paras)\n",
    "\n",
    "\n",
    "def label_get2(start_date, end_date, loanstyle):\n",
    "    '''\n",
    "    get loans with the given loanstyle whose fundtime between start_date & end_date;\n",
    "    paras: start_date: '2019-06-01 00:00:00'\n",
    "    paras: end_date: '2019-07-01 00:00:00'\n",
    "    paras: loanstyle: '绿卡30天1期'\n",
    "    '''\n",
    "    query_name = 'label_get2'\n",
    "    paras = 'start_date={}&end_date={}&loan_type={}'.format(start_date, end_date, loanstyle) \n",
    "    return query_graphsql(query_name, paras)['results'][0]['loanlabelSHOW']\n",
    "\n",
    "\n",
    "#1\n",
    "def reset(node):\n",
    "    '''\n",
    "    '''\n",
    "    query_name = 'reset'\n",
    "    paras = 'node={}'.format(node) \n",
    "    return query_graphsql(query_name, paras)\n",
    "\n",
    "\n",
    "#2\n",
    "def pageRank_train(start_t, end_t, node, maxChange, maxIter, damping, query_name):\n",
    "    '''\n",
    "    '''\n",
    "    paras = 'start_t={}&end_t={}&node={}&maxChange={}&maxIter={}&damping={}'.format(start_t, end_t, node, maxChange,maxIter,damping) \n",
    "    return query_graphsql(query_name, paras)\n",
    "\n",
    "\n",
    "#3\n",
    "def pageRank_appr_files(file_abs_path, query_name):\n",
    "    '''\n",
    "    draft 1 for pageRank in cashbus graph; \n",
    "    Only works for user-device relationship(single edge type & double vertex type);\n",
    "    Only output nodes(type: user or device) with pg_score !=0;\n",
    "    '''\n",
    "    paras = 'file_path={}'.format(file_abs_path) \n",
    "    return query_graphsql(query_name, paras) \n",
    "\n",
    "    \n",
    "def pyG_prepare(st, et, node):\n",
    "    query_name = 'pyG_pre'\n",
    "    paras = 'start_t={}&end_t={}&node={}'.format(st,et,node)\n",
    "    return query_graphsql(query_name, paras) \n",
    "\n",
    "\n",
    "#2\n",
    "def connected_comp_train(start_t, end_t, node):\n",
    "    '''\n",
    "    '''\n",
    "    query_name='conn_comp'\n",
    "    paras = 'start_t={}&end_t={}&node={}'.format(start_t, end_t, node) \n",
    "    return query_graphsql(query_name, paras)\n",
    "\n",
    "\n",
    "#3\n",
    "def connected_comp_appr_files(file_abs_path):\n",
    "    '''\n",
    "    draft 1 for pageRank in cashbus graph; \n",
    "    Only works for user-device relationship(single edge type & double vertex type);\n",
    "    Only output nodes(type: user or device) with pg_score != 0;\n",
    "    '''\n",
    "    paras = 'file_path={}'.format(file_abs_path)\n",
    "    query_name = 'conn_comp_check'\n",
    "    return query_graphsql(query_name, paras)\n",
    "\n",
    "\n",
    "def train(st, et, node_type, reset_bool):\n",
    "    \"\"\"\n",
    "    paras: st: start time of a period, only node within the restriction will be trained and given a pgscore;\n",
    "    paras: et: end time of the period;\n",
    "    paras: node_type: determine which nodetype will be trained;\n",
    "    \"\"\"\n",
    "    assert node_type in [\"Device\", \"PhoneNumber\"]\n",
    "    if reset_bool:\n",
    "        reset(node_type)\n",
    "    pageRank_train(st, \n",
    "                   et, \n",
    "                   node_type, \n",
    "                   10, 3, 0.6,\n",
    "                   \"pageRank_train_{}\".format(node_type.lower()))\n",
    "    return None\n",
    "\n",
    "\n",
    "def test_with_local_files(nodetype, file_path):\n",
    "    \"\"\"\n",
    "    paras: node_type: determine which nodetype will be test;\n",
    "    paras: file_path: only provide a path to save test nodes id;\n",
    "    \"\"\"\n",
    "    test_res2 = pageRank_appr_files(file_path, \n",
    "                                    \"pageRank_appr_files_{}\".format(nodetype.lower()))\n",
    "    user_pg_res = [i['attributes'] for i in test_res2['results'][0]['test_set']]\n",
    "    user_pg_df2 = pd.DataFrame.from_dict(user_pg_res)\n",
    "    user_pg_df2.rename(columns={'prim_id': 'username'}, inplace=True)\n",
    "    return test_res2, user_pg_df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feats;\n",
    "\n",
    "test_st='20190601'\n",
    "test_et='20190604'\n",
    "\n",
    "res = pyG_prepare(test_st, test_et, \"PhoneNumber\")\n",
    "\n",
    "for temp_dic in tqdm(res['results'][0]['vv']):\n",
    "    if 'attributes' in temp_dic:\n",
    "        dic2 = temp_dic['attributes']['vv.@node_date_calls']\n",
    "    lis.append(temp_dic.update(dic2))\n",
    "    if 'attributes' in temp_dic:\n",
    "        temp_dic.pop('attributes')\n",
    "    if 'vv.@node_date_calls' in temp_dic:\n",
    "        temp_dic.pop('vv.@node_date_calls')\n",
    "            \n",
    "final = pd.DataFrame.from_dict(res['results'][0]['vv'])\n",
    "\n",
    "final2df = final.iloc[:,:4].applymap(lambda x: len(x) if type(x)==list else 0)\n",
    "\n",
    "col_names = ['new_{}'.format(i) for i in final2df.columns]\n",
    "\n",
    "final[col_names] = final.iloc[:,:4].applymap(lambda x: len(x) if type(x)==list else 0)\n",
    "\n",
    "final['num_phone'] = final[['v_id']].applymap(lambda x: len(str(x)))\n",
    "\n",
    "final2 = final[['v_id', 'new_20190601','new_20190602','new_20190603','new_20190604']]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "final2.to_csv('/home/tigergraph/GraphProject/OneMonthGraph/Querys/pyG/data/feat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feats; torch;\n",
    "final2 = pd.read_csv('/home/tigergraph/GraphProject/OneMonthGraph/Querys/pyG/data/feat.csv')\n",
    "\n",
    "idx2phone = dict(enumerate(final2.v_id))\n",
    "phone2idx = {v:k for k,v in idx2phone.items()}\n",
    "\n",
    "x = torch.tensor(final2.iloc[:,1:].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get labels；\n",
    "\n",
    "labels = pd.read_csv('/home/tigergraph/GraphProject/OneMonthGraph/Querys/pyG/data/temp1.csv')\n",
    "labels1 = labels[['default_now', 'username']]\n",
    "label_dict = labels1.set_index('username').to_dict()\n",
    "\n",
    "# 序号按照 feat序号；\n",
    "lis = []\n",
    "labeled_phone = labels1.username.astype(str).to_list()\n",
    "for i, phone in enumerate(final2.v_id):\n",
    "    if i %100000==0:\n",
    "        print(i, len(lis), sum(lis))\n",
    "    if phone in labeled_phone:\n",
    "        lis.append(label_dict['default_now'][int(phone)])\n",
    "    else:\n",
    "        lis.append(-1)\n",
    "\n",
    "label_df = pd.DataFrame(lis,columns=['label'])\n",
    "\n",
    "label_df.to_csv('/home/tigergraph/GraphProject/OneMonthGraph/Querys/pyG/data/label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels；\n",
    "label_df = pd.read_csv('/home/tigergraph/GraphProject/OneMonthGraph/Querys/pyG/data/label.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get edges;\n",
    "res = pyG_prepare(test_st, test_et, \"PhoneNumber\")\n",
    "\n",
    "for dic in tqdm(res['results'][0]['vv']):\n",
    "    dic.update(dic['attributes']['vv.@node_date_calls'])\n",
    "\n",
    "\n",
    "for dic in res['results'][0]['vv']:\n",
    "    dic['lis'] = []\n",
    "    for i,v in dic.items():\n",
    "        if i in ['20190601','20190602','20190603','20190604']:\n",
    "            dic['lis'].extend(v)\n",
    "            \n",
    "edges = pd.DataFrame.from_dict(res['results'][0]['vv'])\n",
    "\n",
    "EDGES = []\n",
    "for a, b in tqdm(edges[['lis','v_id']].values):\n",
    "    bb=len(a)*[b]\n",
    "    EDGES.extend(list(zip(a, bb)))\n",
    "\n",
    "pd.DataFrame(EDGES, columns=['source','target']).to_csv('/home/tigergraph/GraphProject/OneMonthGraph/Querys/pyG/data/label.csv',\n",
    "index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# get edges;\n",
    "\n",
    "edges_df = pd.read_csv('/home/tigergraph/GraphProject/OneMonthGraph/Querys/pyG/data/label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SplineConv,GCNConv\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CashBus(InMemoryDataset):\n",
    "    r\"\"\"The citation network datasets \"Cora\", \"CiteSeer\" and \"PubMed\" from the\n",
    "    `\"Revisiting Semi-Supervised Learning with Graph Embeddings\"\n",
    "    <https://arxiv.org/abs/1603.08861>`_ paper.\n",
    "    Nodes represent documents and edges represent citation links.\n",
    "    Training, validation and test splits are given by binary masks.\n",
    "    Args:\n",
    "        root (string): Root directory where the dataset should be saved.\n",
    "        name (string): The name of the dataset (:obj:`\"Cora\"`,\n",
    "            :obj:`\"CiteSeer\"`, :obj:`\"PubMed\"`).\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(CashBus, self).__init__(root, transform, pre_transform)\n",
    "        print('processed_path:{}'.format(self.processed_paths))\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['col_4_dict', 'feat.npz', 'y.npz', 'edges.npz', 'col_name.pkl']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        print('go pl, raw_dir:{}'.format(self.raw_dir))\n",
    "        data = read_cashbus_data(self.raw_dir)\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "        data, slices = self.collate([data])\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

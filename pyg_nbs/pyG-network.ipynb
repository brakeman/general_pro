{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  2,  3,  4],\n",
       "       [ 0,  2,  4,  6,  8],\n",
       "       [ 0,  3,  6,  9, 12],\n",
       "       [ 0,  4,  8, 12, 16]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from scipy.sparse import csgraph\n",
    ">>> G = np.arange(5) * np.arange(5)[:, np.newaxis]\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = [2,3,2,3,3,1]\n",
    "D_ori = np.diag(D)\n",
    "\n",
    "D_neg_1_2 = np.array(D, dtype=float)**(-1)\n",
    "D_neg_1_2 = np.diag(D_neg_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =   [[0,1,0,0,1,0],\n",
    "       [1,0,1,0,1,0],\n",
    "       [0,1,0,1,0,0],\n",
    "       [0,0,1,0,1,1],\n",
    "       [1,1,0,1,0,0],\n",
    "       [0,0,0,1,0,0]]\n",
    "\n",
    "A = np.array(A, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.5       , 0.        , 0.        , 0.5       ,\n",
       "        0.        ],\n",
       "       [0.33333333, 0.        , 0.33333333, 0.        , 0.33333333,\n",
       "        0.        ],\n",
       "       [0.        , 0.5       , 0.        , 0.5       , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.33333333, 0.        , 0.33333333,\n",
       "        0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.        , 0.33333333, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_neg_1_2@A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2., -1.,  0.,  0., -1.,  0.],\n",
       "       [-1.,  3., -1.,  0., -1.,  0.],\n",
       "       [ 0., -1.,  2., -1.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  3., -1., -1.],\n",
       "       [-1., -1.,  0., -1.,  3.,  0.],\n",
       "       [ 0.,  0.,  0., -1.,  0.,  1.]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1 = D_ori - A\n",
    "L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2., -1., -0., -0., -1., -0.],\n",
       "       [-1.,  3., -1., -0., -1., -0.],\n",
       "       [-0., -1.,  2., -1., -0., -0.],\n",
       "       [-0., -0., -1.,  3., -1., -1.],\n",
       "       [-1., -1., -0., -1.,  3., -0.],\n",
       "       [-0., -0., -0., -1., -0.,  1.]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csgraph.laplacian(A, normed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter.utils.gen import gen\n",
    "import torch_scatter\n",
    "import sys\n",
    "import inspect\n",
    "import torch\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.utils import add_remaining_self_loops\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "def scatter_(name, src, index, dim_size=None):\n",
    "    assert name in ['add', 'mean', 'max']\n",
    "\n",
    "    op = getattr(torch_scatter, 'scatter_{}'.format(name))\n",
    "    fill_value = -1e9 if name == 'max' else 0\n",
    "#     print('---------scatter_')\n",
    "#     print('src:{}\\nindex:{}\\n'.format(src.size(), index))\n",
    "    \n",
    "    out = op(src, index, 0, None, dim_size, fill_value)\n",
    "#     print('out:{}'.format(out.size()))\n",
    "#     print('---------scatter_-----------')\n",
    "    if isinstance(out, tuple):\n",
    "        out = out[0]\n",
    "    \n",
    "    if name == 'max':\n",
    "        out[out == fill_value] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "def scatter_add(src, index, dim=-1, out=None, dim_size=None, fill_value=0):\n",
    "\n",
    "    src, out, index, dim = gen(src, index, dim, out, dim_size, fill_value)\n",
    "    res = out.scatter_add_(dim, index, src)\n",
    "#     print(dim,'hhhhh')\n",
    "    return res\n",
    "\n",
    "def glorot(tensor):\n",
    "    if tensor is not None:\n",
    "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))\n",
    "        tensor.data.uniform_(-stdv, stdv)\n",
    "\n",
    "def zeros(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(0)\n",
    "        \n",
    "\n",
    "special_args = [\n",
    "    'edge_index', 'edge_index_i', 'edge_index_j', 'size', 'size_i', 'size_j'\n",
    "]\n",
    "__size_error_msg__ = ('All tensors which should get mapped to the same source '\n",
    "                      'or target nodes must be of same size in dimension 0.')\n",
    "\n",
    "is_python2 = sys.version_info[0] < 3\n",
    "getargspec = inspect.getargspec if is_python2 else inspect.getfullargspec\n",
    "\n",
    "\n",
    "class MessagePassing(torch.nn.Module):\n",
    "    def __init__(self, aggr='add', flow='source_to_target'):\n",
    "        super(MessagePassing, self).__init__()\n",
    "\n",
    "        self.aggr = aggr\n",
    "        assert self.aggr in ['add', 'mean', 'max']\n",
    "\n",
    "        self.flow = flow\n",
    "        assert self.flow in ['source_to_target', 'target_to_source']\n",
    "\n",
    "        self.__message_args__ = getargspec(self.message)[0][1:]\n",
    "#         print('__message_args__:{}'.format(self.__message_args__))\n",
    "        self.__special_args__ = [(i, arg)\n",
    "                                 for i, arg in enumerate(self.__message_args__)\n",
    "                                 if arg in special_args]\n",
    "#         print('__special_args__:{}'.format(self.__special_args__))\n",
    "        self.__message_args__ = [\n",
    "            arg for arg in self.__message_args__ if arg not in special_args\n",
    "        ]\n",
    "#         print('__message_args__:{}'.format(self.__message_args__))\n",
    "        self.__update_args__ = getargspec(self.update)[0][2:]\n",
    "#         print('__update_args__:{}'.format(self.__update_args__))\n",
    "#         print('------------------------------')\n",
    "\n",
    "    def propagate(self, edge_index, size=None, **kwargs):\n",
    "\n",
    "        size = [None, None] if size is None else list(size)\n",
    "#         print(size)\n",
    "        assert len(size) == 2\n",
    "\n",
    "        i, j = (0, 1) if self.flow == 'target_to_source' else (1, 0)\n",
    "        ij = {\"_i\": i, \"_j\": j}\n",
    "\n",
    "        message_args = []\n",
    "        for arg in self.__message_args__:\n",
    "            if arg[-2:] in ij.keys():\n",
    "                tmp = kwargs.get(arg[:-2], None)\n",
    "                if tmp is None:  # pragma: no cover\n",
    "                    message_args.append(tmp)\n",
    "                else:\n",
    "                    idx = ij[arg[-2:]]\n",
    "                    if isinstance(tmp, tuple) or isinstance(tmp, list):\n",
    "                        assert len(tmp) == 2\n",
    "                        if tmp[1 - idx] is not None:\n",
    "                            if size[1 - idx] is None:\n",
    "                                size[1 - idx] = tmp[1 - idx].size(0)\n",
    "                            if size[1 - idx] != tmp[1 - idx].size(0):\n",
    "                                raise ValueError(__size_error_msg__)\n",
    "                        tmp = tmp[idx]\n",
    "                    if size[idx] is None:\n",
    "                        size[idx] = tmp.size(0)\n",
    "                    if size[idx] != tmp.size(0):\n",
    "                        raise ValueError(__size_error_msg__)\n",
    "#                     print('---------------')\n",
    "#                     print('tmp_size:{}'.format(tmp.size()))\n",
    "#                     print('idx:{}'.format(idx))\n",
    "                    tmp = torch.index_select(tmp, 0, edge_index[idx])\n",
    "#                     print('idex_selct:{}'.format(edge_index[idx]))\n",
    "#                     print('tmp_size:{}'.format(tmp.size()))\n",
    "#                     print('~~~~~~~~~~~~~~~')\n",
    "                    message_args.append(tmp)\n",
    "            else:\n",
    "                message_args.append(kwargs.get(arg, None))\n",
    "        size[0] = size[1] if size[0] is None else size[0]\n",
    "        size[1] = size[0] if size[1] is None else size[1]\n",
    "#         print('size:{}'.format(size))\n",
    "        kwargs['edge_index'] = edge_index\n",
    "        kwargs['size'] = size\n",
    "#         print('.keys():{}'.format(kwargs.keys()))\n",
    "#         print('__special_args__:{}'.format(self.__special_args__))\n",
    "        for (idx, arg) in self.__special_args__:\n",
    "            if arg[-2:] in ij.keys():\n",
    "                message_args.insert(idx, kwargs[arg[:-2]][ij[arg[-2:]]])\n",
    "            else:\n",
    "                message_args.insert(idx, kwargs[arg])\n",
    "                \n",
    "#         print('Passing. with message_args:{}'.format(len(message_args)))\n",
    "#         print('args:1 {}'.format(message_args[0].size()))\n",
    "#         print('args:2 {}'.format(message_args[1].size()))\n",
    "\n",
    "        update_args = [kwargs[arg] for arg in self.__update_args__]\n",
    "#         print('message_args:{}'.format(len(message_args)))\n",
    "        out = self.message(*message_args)\n",
    "#         print('---out---1----{}'.format(out.size()))\n",
    "#         print('self.aggr:{}'.format(self.aggr))\n",
    "#         print('edge_Idx_I_size:{}\\nitself:{}'.format(len(edge_index[i]),edge_index[i]))\n",
    "#         print('dim_size:{}'.format(size[i]))\n",
    "        \n",
    "        out = scatter_(self.aggr, out, edge_index[i], dim_size=size[i])\n",
    "#         print('---out---2----{}'.format(out.size())) \n",
    "        out = self.update(out, *update_args)\n",
    "#         print('---out---3----{}'.format(out.size()))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):  # pragma: no cover\n",
    "        r\"\"\"Constructs messages in analogy to :math:`\\phi_{\\mathbf{\\Theta}}`\n",
    "        for each edge in :math:`(i,j) \\in \\mathcal{E}`.\n",
    "        Can take any argument which was initially passed to :meth:`propagate`.\n",
    "        In addition, features can be lifted to the source node :math:`i` and\n",
    "        target node :math:`j` by appending :obj:`_i` or :obj:`_j` to the\n",
    "        variable name, *.e.g.* :obj:`x_i` and :obj:`x_j`.\"\"\"\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out):  # pragma: no cover\n",
    "        r\"\"\"Updates node embeddings in analogy to\n",
    "        :math:`\\gamma_{\\mathbf{\\Theta}}` for each node\n",
    "        :math:`i \\in \\mathcal{V}`.\n",
    "        Takes in the output of aggregation as first argument and any argument\n",
    "        which was initially passed to :meth:`propagate`.\"\"\"\n",
    "\n",
    "        return aggr_out\n",
    "    \n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, improved=False, cached=False,\n",
    "                 bias=True, **kwargs):\n",
    "        super(GCNConv, self).__init__(aggr='add', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        zeros(self.bias)\n",
    "        self.cached_result = None\n",
    "        self.cached_num_edges = None\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def norm(edge_index, num_nodes, edge_weight=None, improved=False,\n",
    "             dtype=None):\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,\n",
    "                                     device=edge_index.device)\n",
    "\n",
    "        fill_value = 1 if not improved else 2\n",
    "        edge_index, edge_weight = add_remaining_self_loops(\n",
    "            edge_index, edge_weight, fill_value, num_nodes)\n",
    "\n",
    "        row, col = edge_index\n",
    "        print('pre_scatter:edgeweight{}\\nrow{}'.format(edge_weight.size(), row.size()))\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        \n",
    "        print('deg_inv:{}'.format(deg_inv_sqrt.size()))\n",
    "        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = torch.matmul(x, self.weight)\n",
    "\n",
    "        if self.cached and self.cached_result is not None:\n",
    "            if edge_index.size(1) != self.cached_num_edges:\n",
    "                raise RuntimeError(\n",
    "                    'Cached {} number of edges, but found {}. Please '\n",
    "                    'disable the caching behavior of this layer by removing '\n",
    "                    'the `cached=True` argument in its constructor.'.format(\n",
    "                        self.cached_num_edges, edge_index.size(1)))\n",
    "\n",
    "        if not self.cached or self.cached_result is None:\n",
    "            self.cached_num_edges = edge_index.size(1)\n",
    "            edge_index, norm = self.norm(edge_index, x.size(0), edge_weight,\n",
    "                                         self.improved, x.dtype)\n",
    "            self.cached_result = edge_index, norm\n",
    "\n",
    "        edge_index, norm = self.cached_result\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "#         print('x_j:{}'.format(x_j.size()))\n",
    "#         print('norm:{}'.format(norm.size()))\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        if self.bias is not None:\n",
    "            aggr_out = aggr_out + self.bias\n",
    "        return aggr_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "dataset = 'Cora'\n",
    "\n",
    "dataset = Planetoid('/home/qibo/all_project/Graph反欺诈/', dataset, T.TargetIndegree())\n",
    "data = dataset[0]\n",
    "\n",
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.uint8)\n",
    "data.train_mask[:data.num_nodes - 1000] = 1\n",
    "data.val_mask = None\n",
    "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.uint8)\n",
    "data.test_mask[data.num_nodes - 500:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data.edge_index\n",
    "\n",
    "app = torch.tensor([[2707],[8888]], dtype=torch.long)\n",
    "\n",
    "new_edge = torch.cat([temp, app], dim=-1)\n",
    "\n",
    "data.edge_index = new_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [ 633, 1862, 2582,  ..., 1473, 2706, 8888]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index out of range at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:193",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7b57f4badfb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qb_vir_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-7b57f4badfb5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qb_vir_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qb_vir_env/lib/python3.6/site-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qb_vir_env/lib/python3.6/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__size_error_msg__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0mmessage_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:193"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = GATConv(dataset.num_features, 8, heads=8, dropout=0.6)\n",
    "#         # On the Pubmed dataset, use heads=8 in conv2.\n",
    "#         self.conv2 = GATConv(\n",
    "#             8 * 8, dataset.num_classes, heads=1, concat=True, dropout=0.6)\n",
    "\n",
    "#     def forward(self, data):\n",
    "#         x = F.dropout(data.x, p=0.6, training=self.training)\n",
    "#         x = F.elu(self.conv1(x, data.edge_index))\n",
    "#         x = F.dropout(x, p=0.6, training=self.training)\n",
    "#         x = self.conv2(x, data.edge_index)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "    \n",
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = SplineConv(dataset.num_features, 16, dim=1, kernel_size=2)\n",
    "#         self.conv2 = SplineConv(16, dataset.num_classes, dim=1, kernel_size=2)\n",
    "\n",
    "#     def forward(self):\n",
    "#         x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.conv2(x, edge_index, edge_attr)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "    \n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(2):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(data.edge_index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13265"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2708 + 10557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[10556, 1], edge_index=[2, 10557], test_mask=[2708], train_mask=[2708], x=[2708, 1433], y=[2708])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SplineConv, GCNConv\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_mask_idx(labels_df, train_valid_split=0.8):\n",
    "    train_idx = labels_df[labels_df.fundtime<'2019-06-03 00:00:00'].username.tolist()\n",
    "    test_idx = labels_df[labels_df.fundtime>='2019-06-04 00:00:00'].username.tolist()\n",
    "    split_idx = int(len(train_idx)*train_valid_split)\n",
    "    train = train_idx[:split_idx]\n",
    "    valid = train_idx[split_idx:]\n",
    "    print(len(train), len(valid), len(test_idx))\n",
    "    return train, valid, test_idx\n",
    "\n",
    "def _get_final_label(labels, new_x_phone2idx):\n",
    "    \n",
    "    label_dict = labels[['username', 'default_now']].set_index('username').to_dict()['default_now']\n",
    "    train_phone, valid_phone, test_phone = __get_mask_idx(labels)\n",
    "    fake_labels = np.zeros(len(new_x_phone2idx))-1\n",
    "\n",
    "    for phone in label_dict:\n",
    "        idx = new_x_phone2idx[str(phone)]\n",
    "        fake_labels[idx] = label_dict[int(phone)]   \n",
    "\n",
    "    train_mask = [new_x_phone2idx[str(phone)] for phone in train_phone]\n",
    "    fake_train_labels = np.zeros(len(new_x_phone2idx))\n",
    "    fake_train_labels[train_mask] = 1\n",
    "\n",
    "    valid_mask = [new_x_phone2idx[str(phone)] for phone in valid_phone]\n",
    "    fake_valid_labels = np.zeros(len(new_x_phone2idx))\n",
    "    fake_valid_labels[valid_mask] = 1\n",
    "    \n",
    "    test_mask = [new_x_phone2idx[str(phone)] for phone in test_phone]\n",
    "    fake_test_labels = np.zeros(len(new_x_phone2idx))\n",
    "    fake_test_labels[test_mask] = 1\n",
    "    \n",
    "    return fake_labels, fake_train_labels, fake_valid_labels, fake_test_labels\n",
    "\n",
    "\n",
    "def _add_new_feat(x, test_df):\n",
    "    not_in_edge_lis = []\n",
    "    for i in test_df.username:\n",
    "        if str(i) not in x:\n",
    "            x[str(i)] = [0, 0, 0, 0]\n",
    "            not_in_edge_lis.append(str(i))\n",
    "    return x, not_in_edge_lis\n",
    "\n",
    "\n",
    "def _add_new_edge(edge, test_df, not_in_edge_lis):\n",
    "    for i in test_df.username:\n",
    "        if str(i) in not_in_edge_lis:\n",
    "            edge.append([str(i), str(i)])\n",
    "    return edge\n",
    "    \n",
    "def _add_phone2ix(x_phone2idx, not_in_edge_lis):\n",
    "    old_len = len(x_phone2idx)\n",
    "    i=0\n",
    "    for new_phone in not_in_edge_lis:\n",
    "        x_phone2idx[new_phone] = old_len+i\n",
    "        i+=1\n",
    "    return x_phone2idx\n",
    "\n",
    "def get_all_info(x, edge, x_phone2idx, test_df):\n",
    "    print(len(x), len(edge), len(x_phone2idx))\n",
    "    print('--------------------------')\n",
    "    x, not_in_edge_lis = _add_new_feat(x, test_df)\n",
    "    edge = _add_new_edge(edge, test_df, not_in_edge_lis)\n",
    "    x_phone2idx = _add_phone2ix(x_phone2idx, not_in_edge_lis)\n",
    "    print(len(x), len(edge), len(x_phone2idx))\n",
    "    fake_labels, train_mask, valid_mask, test_mask = _get_final_label(test_df, x_phone2idx)\n",
    "    return x, edge, x_phone2idx, fake_labels, train_mask, valid_mask, test_mask\n",
    "    \n",
    "\n",
    "def read_cashbus_data(root):\n",
    "    \n",
    "    ##################### finish add test infos into the graph ############################\n",
    "    with open(root+'/feat.json') as json_file:\n",
    "        x = json.load(json_file)\n",
    "    with open(root+'/x_phone2idx.json') as json_file:\n",
    "        x_phone2idx = json.load(json_file)\n",
    "    with open(root+'/edge.json') as json_file:\n",
    "        edge = json.load(json_file)\n",
    "    labels = pd.read_csv(root+'/four_days_label.csv')\n",
    "    x, edge, x_phone2idx, y, train_mask, valid_mask, test_mask = get_all_info(x, edge, x_phone2idx, labels)  \n",
    "    \n",
    "    ##################### finish add test infos into the graph ############################\n",
    "    \n",
    "    feat_mat = []\n",
    "    for k,v in tqdm(x.items()):\n",
    "        feat_mat.append(v)\n",
    "    x = torch.tensor(feat_mat, dtype =torch.float)    \n",
    "    y = torch.tensor(y, dtype=torch.int64).squeeze()\n",
    "    edge = np.array(edge).T\n",
    "    row1 = [x_phone2idx[str(i)] for i in edge[0]]\n",
    "    row2 = [x_phone2idx[str(i)] for i in edge[1]]\n",
    "    new_edges = torch.tensor(np.stack([row1, row2]))\n",
    "    \n",
    "    ##################### finish all ############################\n",
    "    data = Data(x=x, edge_index=new_edges, y=y)\n",
    "    data.train_mask = torch.tensor(train_mask, dtype=torch.uint8)\n",
    "    data.val_mask = torch.tensor(valid_mask, dtype=torch.uint8)\n",
    "    data.test_mask = torch.tensor(test_mask, dtype=torch.uint8)\n",
    "    return data\n",
    "\n",
    "class CashBus(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(CashBus, self).__init__(root, transform, pre_transform)\n",
    "        print('processed_path:{}'.format(self.processed_paths))\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['feat.json', 'x_phone2idx.json', 'edge.json', 'four_days_label.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data11.pt'\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        print('go pl, raw_dir:{}'.format(self.raw_dir))\n",
    "        data = read_cashbus_data(self.raw_dir)\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "        data, slices = self.collate([data])\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_path:['/home/qibo/all_project/Graph反欺诈/PYG/processed/data11.pt']\n",
      "0.26741838455200195\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "root = '/home/qibo/all_project/Graph反欺诈/PYG/'\n",
    "dataset = CashBus(root)\n",
    "data = dataset[0]\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16, cached=True)\n",
    "        self.conv1_1 = GCNConv(16, 16, cached=True)\n",
    "        self.conv1_2 = GCNConv(16, 16, cached=True)\n",
    "        self.conv2 = GCNConv(16, int(dataset.num_classes), cached=True)\n",
    "\n",
    "    def forward(self):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "#         x = F.relu(self.conv1_1(x, edge_index))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "        \n",
    "#         x = F.relu(self.conv1_2(x, edge_index))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\n",
      "use 60.82511258125305 seconds\n",
      "0.07266795195017055\n",
      "0.0764218009478673\n",
      "0.07941313460642757\n",
      "Epoch: 001, Train: 0.6484, Val: 0.6374, Test: 0.3570\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        print(data.y[mask].sum().item() / len(data.y[mask]))\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 2):\n",
    "    print('epoch:{}'.format(epoch))\n",
    "    st = time.time()\n",
    "    train()\n",
    "    print('use {} seconds'.format(time.time() - st))\n",
    "    train_acc, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    print(log.format(epoch, train_acc, best_val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
